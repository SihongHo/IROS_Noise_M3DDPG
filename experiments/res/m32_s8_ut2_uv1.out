0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -28.713888503346293, agent episode reward: [0.8420441256163191, 0.7392267860333971, 0.8604999593978581, 0.8208813115381722, -18.106671990579496, -13.869868695352546], time: 247.681
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -10.159128132897905, agent episode reward: [1.1540516659272813, 1.7253214434522774, 1.7546319064288922, 1.6054163965013137, -9.68258689482773, -6.715962650379938], time: 318.812
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 6.909010898073611, agent episode reward: [2.7523517702550806, 3.0206669642849753, 3.400588267617268, 2.69197893061846, -2.940720128367277, -2.015854906334895], time: 322.767
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 13.126271367477342, agent episode reward: [4.833905940148046, 4.798826837912224, 4.963617605068165, 4.394064998045649, -3.4198475368777084, -2.4442964768190314], time: 328.36
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 18.142428873418154, agent episode reward: [6.167473153007479, 6.081791713658797, 6.302994292473791, 5.84596673237063, -3.2518108923265165, -3.00398612576603], time: 328.815
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 21.792820225182652, agent episode reward: [7.220477937805267, 6.777283469108197, 7.2848519941702286, 7.0636060781132946, -3.516916520257988, -3.036482733756351], time: 326.076
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 23.293606622301635, agent episode reward: [7.788370028035127, 7.453515481889477, 7.9239459026482875, 7.568484006057378, -3.6401631640157404, -3.8005456323128928], time: 329.14
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 26.477711227085226, agent episode reward: [8.918906152016454, 8.418162971452727, 8.814418144095448, 8.716415698656093, -3.9437550598753695, -4.446436679260127], time: 329.319
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 30.34798655933706, agent episode reward: [10.056492820469527, 9.724447099958114, 10.042744720897733, 10.005032883849944, -4.787193236415903, -4.693537729422358], time: 329.668
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 29.501244577381666, agent episode reward: [9.797450188355684, 9.630130658087735, 9.829828104626515, 9.860461481190903, -5.118627670203746, -4.497998184675424], time: 329.554
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 36.82922520372033, agent episode reward: [12.048779828835658, 11.973447758352762, 12.11019988953906, 12.110463990108421, -5.842236340143254, -5.571429922972311], time: 329.145
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 36.71698757612801, agent episode reward: [11.964414051742434, 12.105109818316405, 12.124089089840872, 12.167002737173526, -5.944364219217505, -5.69926390172772], time: 331.477
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 34.624284996159524, agent episode reward: [11.310802183635488, 11.323603028789599, 11.461058601957406, 11.448047131662108, -5.804969247551397, -5.114256702333678], time: 328.644
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 36.44643083018863, agent episode reward: [12.167103519632368, 12.269201434536756, 12.270400680504943, 12.270662056457871, -6.628805903560958, -5.902130957382349], time: 329.503
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 36.746436733085936, agent episode reward: [12.215211786303557, 12.327380047469026, 12.380012214632734, 12.271274857896719, -6.121990434784597, -6.3254517384315], time: 331.725
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 37.92034297313662, agent episode reward: [12.624765632067131, 12.637342452127127, 12.667510203610524, 12.582946142388213, -6.001002864880774, -6.591218592175596], time: 331.18
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 34.04969259012031, agent episode reward: [11.775702635870347, 11.743093803080656, 11.725495916017445, 11.62832380973614, -6.274670200459257, -6.548253374125021], time: 330.322
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 36.72780739867334, agent episode reward: [12.223931633383243, 12.220934910803434, 12.233416053227177, 12.145122761815504, -5.392461271676573, -6.703136688879444], time: 330.6
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 32.780251286829866, agent episode reward: [11.020528928368668, 10.965253363840745, 10.912112850665554, 10.940779135065048, -4.918979319332362, -6.139443671777782], time: 330.177
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 31.244982185359923, agent episode reward: [10.83888935040643, 10.764509451920533, 10.80781580453588, 10.72072323259297, -6.291681582110202, -5.595274071985688], time: 329.512
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 34.82305868825878, agent episode reward: [11.968959115355656, 11.873892086314507, 11.877456305054789, 11.896747183151671, -7.523209728384672, -5.270786273233172], time: 329.984
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 26.776444070091895, agent episode reward: [9.808359083254135, 9.670751438104748, 9.733955059788618, 9.701937537675036, -7.238189234150157, -4.900369814580492], time: 329.192
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 25.39991725067894, agent episode reward: [9.33502177020143, 9.123804735116293, 9.22935085803556, 9.18531796790442, -6.547331931994838, -4.926246148583922], time: 331.359
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 23.46800654361578, agent episode reward: [8.904061407667141, 8.697122510352939, 8.793210389413769, 8.76034612071713, -6.917737092828964, -4.768996791706241], time: 329.791
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 17.494618134279577, agent episode reward: [6.653045287525328, 6.466320450712919, 6.5514890735269535, 6.528101697717065, -4.500802739859319, -4.203535635343369], time: 327.91
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 17.742108685063556, agent episode reward: [7.2721088065114525, 7.132173514874793, 7.151067926617544, 7.137518877567319, -5.006723872814118, -5.944036567693436], time: 326.28
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 19.27406281094611, agent episode reward: [7.2847863875566565, 7.0261063533901345, 7.08724232005277, 7.144183556422713, -4.033631731920205, -5.234624074555957], time: 327.235
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 18.651821003640226, agent episode reward: [6.756602571668101, 6.641124332793063, 6.606852274962878, 6.619645581644469, -4.266920102547823, -3.7054836548804624], time: 324.546
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 18.152766861265416, agent episode reward: [6.5774085890129514, 6.448525284364004, 6.440605781045399, 6.534784339351497, -4.495903494717046, -3.352653637791389], time: 319.159
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 18.038182220558, agent episode reward: [6.499478045195795, 6.380222168585164, 6.39629732157999, 6.392577222521007, -3.985201925109963, -3.6451906122139945], time: 318.234
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 15.569748691459022, agent episode reward: [5.666704992874258, 5.563417296784922, 5.527109897360466, 5.576723216454251, -3.6951532220170837, -3.069053489997792], time: 318.534
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 13.575784191908248, agent episode reward: [5.434562252170689, 5.299700538245173, 5.277135671396556, 5.354947659394368, -5.01241400972266, -2.7781479195758743], time: 318.581
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 12.556571805218104, agent episode reward: [4.814781546711738, 4.845361689223468, 4.761542010466817, 4.8383524589319515, -3.550553325812358, -3.1529125743035142], time: 319.403
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 14.004127964776966, agent episode reward: [5.491904967647986, 5.479237451151186, 5.4798826121455715, 5.516784878946452, -4.628607106552329, -3.3350748385619], time: 318.937
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 10.481948886534854, agent episode reward: [4.356575705707733, 4.348509899883689, 4.22762536129242, 4.375150843914964, -3.768143788263123, -3.057769136000828], time: 319.551
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 10.895061684427382, agent episode reward: [4.8268642295233, 4.8241756478354, 4.742938310196267, 4.8328773793384805, -4.227560967404799, -4.1042329150612655], time: 317.681
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 10.591044430341942, agent episode reward: [4.5016254319213935, 4.475971983712719, 4.37000181979473, 4.52831383198704, -4.339492134647544, -2.9453765024263956], time: 320.216
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 11.877427632751884, agent episode reward: [4.649526537265135, 4.663897270886045, 4.657005290175602, 4.760492968111397, -4.225297135497406, -2.6281972981888906], time: 317.008
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 10.990910110907498, agent episode reward: [4.425310182693517, 4.356121744232502, 4.291625936844684, 4.431180000126184, -3.651247454865298, -2.862080298124093], time: 316.858
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 15.211270165020723, agent episode reward: [5.571545404061982, 5.6016209559355055, 5.518317160147809, 5.683175668919317, -4.429631978770865, -2.7337570452730233], time: 318.425
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 13.362016759820788, agent episode reward: [5.164205825083935, 5.114171294939162, 5.17178310638057, 5.305828324483135, -3.818584429795219, -3.5753873612707965], time: 315.582
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 10.661093821217777, agent episode reward: [4.220610608483724, 4.179668038766895, 4.278595477920471, 4.2680572378747295, -4.152262688298047, -2.1335748535299954], time: 316.111
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 10.720676015084148, agent episode reward: [4.820275577381712, 4.6998120960690795, 4.826793670821149, 4.897551778462488, -5.344073075688685, -3.179684031961595], time: 316.01
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 11.309236855492195, agent episode reward: [5.014165277338816, 4.9413867441767305, 4.8744227369751645, 5.041949385748449, -4.933824721762165, -3.6288625669848025], time: 317.98
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 10.500045314432084, agent episode reward: [4.7222366165956, 4.447998824892358, 4.572852044315125, 4.731979384841405, -5.10516231144382, -2.869859244768585], time: 316.021
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 12.35714093114294, agent episode reward: [4.972234783863789, 4.863922941858616, 5.009887279146342, 5.086295423995892, -4.421807608808493, -3.1533918889132044], time: 322.152
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 12.721495299035071, agent episode reward: [5.417514059253729, 5.265611933346447, 5.303375930805242, 5.3855764742113985, -2.996812574932787, -5.653770523648959], time: 316.226
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 15.52109795252117, agent episode reward: [6.012960948847511, 5.835981173102862, 5.88072738912673, 6.029697090299772, -3.5831530463269363, -4.65511560252877], time: 316.527
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 16.378234798700984, agent episode reward: [6.046048999396929, 5.849530956853199, 5.994810525048258, 5.994282580301167, -3.3390487146449765, -4.1673895482535945], time: 316.178
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 16.191084003059366, agent episode reward: [5.994318187550652, 5.702142147220352, 5.737788405758289, 5.974782802323032, -3.4885610861918646, -3.7293864536010988], time: 316.732
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 19.424422070324763, agent episode reward: [6.894126534667257, 6.616935620199807, 6.692606318985675, 6.874679212486004, -3.1868660327122953, -4.467059583301682], time: 315.391
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 17.11482040806683, agent episode reward: [6.125508660598824, 5.870409450160469, 5.970575609662194, 6.114512914442248, -3.4773640852067627, -3.488822141590143], time: 314.286
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 18.15895003826261, agent episode reward: [6.500731366483995, 6.095631982889429, 6.3308495177727, 6.445554591436774, -4.058839206887428, -3.154978213432859], time: 314.623
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 19.141171476847923, agent episode reward: [6.697556087514191, 6.262507131009621, 6.516797937875614, 6.636226911939062, -3.5650513925234675, -3.4068651989670973], time: 313.01
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 20.14681803394248, agent episode reward: [6.846281819678473, 6.485195901401763, 6.6181242040116395, 6.768472435387337, -3.3533109868037427, -3.217945339732989], time: 311.376
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 23.346449891739233, agent episode reward: [7.942041682279681, 7.627852003894276, 7.7862030102060364, 7.717558091547342, -4.676563111486301, -3.050641784701801], time: 312.843
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 21.38135367560028, agent episode reward: [7.373219031824252, 7.083956118818187, 7.198770040466185, 7.262621014297872, -4.055667036074226, -3.4815454937319923], time: 317.464
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 24.499144271041235, agent episode reward: [8.259029483427208, 8.03878794585863, 8.039041222484052, 7.978982852295896, -4.187876588724512, -3.6288206443000384], time: 312.035
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 24.05727350570463, agent episode reward: [8.05788656998312, 7.95693468998927, 7.9878725650748965, 7.845988365879095, -4.511628165440787, -3.2797805197809606], time: 314.214
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 19.77577881104015, agent episode reward: [6.726182322368304, 6.643374897139216, 6.628538239530706, 6.509183383944311, -3.720071069922259, -3.0114289620201267], time: 290.139
...Finished total of 60001 episodes.
