0 good agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05]
1 good agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05]
2 good agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 0 adversaries
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
steps: 24975, episodes: 1000, mean episode reward: -223.18573663333308, time: 102.724
steps: 49975, episodes: 2000, mean episode reward: -247.30149244108512, time: 127.369
steps: 74975, episodes: 3000, mean episode reward: -190.82930181795172, time: 126.876
steps: 99975, episodes: 4000, mean episode reward: -185.6862940233877, time: 127.184
steps: 124975, episodes: 5000, mean episode reward: -178.4029737154568, time: 126.538
steps: 149975, episodes: 6000, mean episode reward: -172.46261373308207, time: 125.997
steps: 174975, episodes: 7000, mean episode reward: -167.89455597493733, time: 126.983
steps: 199975, episodes: 8000, mean episode reward: -165.43114948970032, time: 127.123
steps: 224975, episodes: 9000, mean episode reward: -163.63624187556823, time: 126.773
steps: 249975, episodes: 10000, mean episode reward: -162.27886514418876, time: 126.239
steps: 274975, episodes: 11000, mean episode reward: -159.16743674525443, time: 126.66
steps: 299975, episodes: 12000, mean episode reward: -157.69426254019345, time: 126.415
steps: 324975, episodes: 13000, mean episode reward: -157.85313572631887, time: 126.64
steps: 349975, episodes: 14000, mean episode reward: -155.69760937906764, time: 126.935
steps: 374975, episodes: 15000, mean episode reward: -155.9811849863596, time: 127.718
steps: 399975, episodes: 16000, mean episode reward: -153.58113058278653, time: 126.957
steps: 424975, episodes: 17000, mean episode reward: -153.40721119768818, time: 126.604
steps: 449975, episodes: 18000, mean episode reward: -153.01358995566522, time: 127.493
steps: 474975, episodes: 19000, mean episode reward: -152.3734782601174, time: 127.409
steps: 499975, episodes: 20000, mean episode reward: -152.19668336241097, time: 128.022
steps: 524975, episodes: 21000, mean episode reward: -152.9208150132281, time: 127.527
steps: 549975, episodes: 22000, mean episode reward: -153.25494038005382, time: 128.106
steps: 574975, episodes: 23000, mean episode reward: -153.80216447812919, time: 126.701
steps: 599975, episodes: 24000, mean episode reward: -150.5513459411607, time: 126.664
steps: 624975, episodes: 25000, mean episode reward: -150.4298083259923, time: 127.174
steps: 649975, episodes: 26000, mean episode reward: -149.72173789662983, time: 127.141
steps: 674975, episodes: 27000, mean episode reward: -149.20108537281277, time: 126.672
steps: 699975, episodes: 28000, mean episode reward: -149.09558240508096, time: 126.787
steps: 724975, episodes: 29000, mean episode reward: -149.14032357288218, time: 127.052
steps: 749975, episodes: 30000, mean episode reward: -148.0514450192297, time: 127.168
steps: 774975, episodes: 31000, mean episode reward: -147.67189381656056, time: 126.712
steps: 799975, episodes: 32000, mean episode reward: -146.4563393702917, time: 127.284
steps: 824975, episodes: 33000, mean episode reward: -145.47517398853, time: 127.024
steps: 849975, episodes: 34000, mean episode reward: -145.64042571666133, time: 127.227
steps: 874975, episodes: 35000, mean episode reward: -144.15289520463034, time: 127.609
steps: 899975, episodes: 36000, mean episode reward: -143.9596116320488, time: 127.621
steps: 924975, episodes: 37000, mean episode reward: -143.7931873532986, time: 127.05
steps: 949975, episodes: 38000, mean episode reward: -144.04567068135793, time: 127.58
steps: 974975, episodes: 39000, mean episode reward: -143.52153297483764, time: 127.204
steps: 999975, episodes: 40000, mean episode reward: -142.94145325791743, time: 126.28
steps: 1024975, episodes: 41000, mean episode reward: -142.88389578983, time: 127.32
steps: 1049975, episodes: 42000, mean episode reward: -142.01168411350716, time: 127.061
steps: 1074975, episodes: 43000, mean episode reward: -144.0899353046043, time: 126.382
steps: 1099975, episodes: 44000, mean episode reward: -143.61643353045488, time: 126.721
steps: 1124975, episodes: 45000, mean episode reward: -141.93383250918973, time: 126.806
steps: 1149975, episodes: 46000, mean episode reward: -143.75085353305923, time: 127.367
steps: 1174975, episodes: 47000, mean episode reward: -143.33181373942986, time: 127.171
steps: 1199975, episodes: 48000, mean episode reward: -142.35061036926186, time: 127.547
steps: 1224975, episodes: 49000, mean episode reward: -142.00029328488722, time: 126.945
steps: 1249975, episodes: 50000, mean episode reward: -142.47666157134782, time: 126.898
steps: 1274975, episodes: 51000, mean episode reward: -140.06985669064895, time: 127.434
steps: 1299975, episodes: 52000, mean episode reward: -140.04870075765223, time: 127.292
steps: 1324975, episodes: 53000, mean episode reward: -141.06467205639237, time: 126.943
steps: 1349975, episodes: 54000, mean episode reward: -140.1951583084886, time: 127.862
steps: 1374975, episodes: 55000, mean episode reward: -139.6241359889086, time: 126.79
steps: 1399975, episodes: 56000, mean episode reward: -139.39641656627253, time: 126.907
steps: 1424975, episodes: 57000, mean episode reward: -138.18402160564372, time: 126.561
steps: 1449975, episodes: 58000, mean episode reward: -138.827778710872, time: 116.706
steps: 1474975, episodes: 59000, mean episode reward: -136.0098434704537, time: 91.455
steps: 1499975, episodes: 60000, mean episode reward: -138.8220825468873, time: 91.758
...Finished total of 60001 episodes.
