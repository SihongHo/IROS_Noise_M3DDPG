0 bad agents
1 good agents
Using good policy maddpg and bad policy maddpg with 1 adversaries
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
maddpg vs maddpg steps: 24975, episodes: 1000, mean episode reward: -26.6624277862024, agent episode reward: [1.3421230616269586, -28.004550847829357], time: 40.261
maddpg vs maddpg steps: 49975, episodes: 2000, mean episode reward: -20.811101956467915, agent episode reward: [-0.7891619887683765, -20.021939967699538], time: 51.192
maddpg vs maddpg steps: 74975, episodes: 3000, mean episode reward: -13.472772418557525, agent episode reward: [-4.836058357734346, -8.63671406082318], time: 50.489
maddpg vs maddpg steps: 99975, episodes: 4000, mean episode reward: -11.31792059538325, agent episode reward: [-4.039986566435932, -7.277934028947318], time: 51.046
maddpg vs maddpg steps: 124975, episodes: 5000, mean episode reward: -10.31321054935574, agent episode reward: [-3.18268405810983, -7.1305264912459085], time: 52.261
maddpg vs maddpg steps: 149975, episodes: 6000, mean episode reward: -10.348559245155556, agent episode reward: [-3.1923062197235628, -7.156253025431994], time: 52.18
maddpg vs maddpg steps: 174975, episodes: 7000, mean episode reward: -10.235694673417845, agent episode reward: [-2.8975979719124845, -7.338096701505362], time: 51.757
maddpg vs maddpg steps: 199975, episodes: 8000, mean episode reward: -10.434898901886353, agent episode reward: [-3.226054791331915, -7.208844110554437], time: 50.98
maddpg vs maddpg steps: 224975, episodes: 9000, mean episode reward: -10.359278778590811, agent episode reward: [-2.875763479003526, -7.483515299587285], time: 49.588
maddpg vs maddpg steps: 249975, episodes: 10000, mean episode reward: -10.918321154176285, agent episode reward: [-3.010738957260788, -7.907582196915497], time: 51.527
maddpg vs maddpg steps: 274975, episodes: 11000, mean episode reward: -10.153788115944618, agent episode reward: [-2.4967645475543767, -7.657023568390242], time: 49.961
maddpg vs maddpg steps: 299975, episodes: 12000, mean episode reward: -9.966668697785948, agent episode reward: [-2.472420826884607, -7.494247870901341], time: 50.74
maddpg vs maddpg steps: 324975, episodes: 13000, mean episode reward: -9.849343886021593, agent episode reward: [-2.025382280069712, -7.823961605951883], time: 52.354
maddpg vs maddpg steps: 349975, episodes: 14000, mean episode reward: -10.20016481142372, agent episode reward: [-1.9947734924999823, -8.205391318923738], time: 52.97
maddpg vs maddpg steps: 374975, episodes: 15000, mean episode reward: -9.750163683306583, agent episode reward: [-2.0137858994413764, -7.7363777838652075], time: 52.847
maddpg vs maddpg steps: 399975, episodes: 16000, mean episode reward: -9.524281595442128, agent episode reward: [-1.6971046971950121, -7.827176898247113], time: 52.704
maddpg vs maddpg steps: 424975, episodes: 17000, mean episode reward: -9.691304039059123, agent episode reward: [-1.9963711839431124, -7.6949328551160106], time: 50.709
maddpg vs maddpg steps: 449975, episodes: 18000, mean episode reward: -9.76911839354649, agent episode reward: [-1.436327226282405, -8.332791167264084], time: 52.36
maddpg vs maddpg steps: 474975, episodes: 19000, mean episode reward: -9.83423500022096, agent episode reward: [-1.9785261704116917, -7.855708829809268], time: 51.738
maddpg vs maddpg steps: 499975, episodes: 20000, mean episode reward: -9.611058141413231, agent episode reward: [-1.83039295448092, -7.780665186932313], time: 50.977
maddpg vs maddpg steps: 524975, episodes: 21000, mean episode reward: -9.395326323110465, agent episode reward: [-1.8615060444341152, -7.533820278676352], time: 52.662
maddpg vs maddpg steps: 549975, episodes: 22000, mean episode reward: -9.905482325427217, agent episode reward: [-1.8436735083819, -8.061808817045314], time: 52.189
maddpg vs maddpg steps: 574975, episodes: 23000, mean episode reward: -9.763654908669578, agent episode reward: [-1.997235306277127, -7.766419602392451], time: 50.047
maddpg vs maddpg steps: 599975, episodes: 24000, mean episode reward: -9.326495190134988, agent episode reward: [-1.604824020669793, -7.721671169465195], time: 50.7
maddpg vs maddpg steps: 624975, episodes: 25000, mean episode reward: -9.617513794736382, agent episode reward: [-2.068595436823847, -7.548918357912535], time: 51.634
maddpg vs maddpg steps: 649975, episodes: 26000, mean episode reward: -9.385491311370595, agent episode reward: [-1.5020921709035033, -7.883399140467093], time: 51.945
maddpg vs maddpg steps: 674975, episodes: 27000, mean episode reward: -9.776931215124524, agent episode reward: [-1.7106670922414695, -8.066264122883053], time: 50.988
maddpg vs maddpg steps: 699975, episodes: 28000, mean episode reward: -9.338608498777091, agent episode reward: [-1.3912712588462426, -7.947337239930852], time: 52.31
maddpg vs maddpg steps: 724975, episodes: 29000, mean episode reward: -9.831617149363218, agent episode reward: [-1.7648732584319824, -8.066743890931237], time: 50.209
maddpg vs maddpg steps: 749975, episodes: 30000, mean episode reward: -9.579077510960932, agent episode reward: [-1.4357851173969325, -8.143292393563998], time: 48.642
maddpg vs maddpg steps: 774975, episodes: 31000, mean episode reward: -9.815985260590455, agent episode reward: [-1.7206692948378541, -8.0953159657526], time: 49.149
maddpg vs maddpg steps: 799975, episodes: 32000, mean episode reward: -9.647539151874243, agent episode reward: [-1.6135986250569627, -8.033940526817279], time: 52.577
maddpg vs maddpg steps: 824975, episodes: 33000, mean episode reward: -9.709714323584649, agent episode reward: [-1.4890190333693467, -8.220695290215302], time: 52.104
maddpg vs maddpg steps: 849975, episodes: 34000, mean episode reward: -9.67477000145303, agent episode reward: [-1.3455437938469785, -8.32922620760605], time: 51.807
maddpg vs maddpg steps: 874975, episodes: 35000, mean episode reward: -9.360363930777293, agent episode reward: [-1.0026024717895017, -8.35776145898779], time: 52.194
maddpg vs maddpg steps: 899975, episodes: 36000, mean episode reward: -9.737241022799463, agent episode reward: [-0.859647518046046, -8.877593504753419], time: 51.954
maddpg vs maddpg steps: 924975, episodes: 37000, mean episode reward: -10.104997988726613, agent episode reward: [-0.9194281562014851, -9.185569832525127], time: 51.486
maddpg vs maddpg steps: 949975, episodes: 38000, mean episode reward: -10.354016451915244, agent episode reward: [-1.3402829955803042, -9.01373345633494], time: 51.428
maddpg vs maddpg steps: 974975, episodes: 39000, mean episode reward: -9.856907702995825, agent episode reward: [-1.1994953788208127, -8.657412324175011], time: 52.499
maddpg vs maddpg steps: 999975, episodes: 40000, mean episode reward: -10.015139783415265, agent episode reward: [-1.5208404493236238, -8.49429933409164], time: 52.585
maddpg vs maddpg steps: 1024975, episodes: 41000, mean episode reward: -9.481251327157496, agent episode reward: [-1.3445190999415846, -8.13673222721591], time: 50.735
maddpg vs maddpg steps: 1049975, episodes: 42000, mean episode reward: -10.03433333152338, agent episode reward: [-1.6094921446973816, -8.424841186825997], time: 52.263
maddpg vs maddpg steps: 1074975, episodes: 43000, mean episode reward: -9.70246651283419, agent episode reward: [-2.0676827100139863, -7.634783802820204], time: 53.048
maddpg vs maddpg steps: 1099975, episodes: 44000, mean episode reward: -10.204879439278413, agent episode reward: [-1.8388806236245234, -8.365998815653889], time: 52.655
maddpg vs maddpg steps: 1124975, episodes: 45000, mean episode reward: -9.771785858948853, agent episode reward: [-1.4676488457746402, -8.304137013174213], time: 53.608
maddpg vs maddpg steps: 1149975, episodes: 46000, mean episode reward: -9.633422504783997, agent episode reward: [-1.765557184508756, -7.867865320275242], time: 52.64
maddpg vs maddpg steps: 1174975, episodes: 47000, mean episode reward: -9.679012490297612, agent episode reward: [-1.8941625558714041, -7.784849934426209], time: 52.828
maddpg vs maddpg steps: 1199975, episodes: 48000, mean episode reward: -9.344292278353336, agent episode reward: [-1.6664878010300235, -7.677804477323313], time: 53.293
maddpg vs maddpg steps: 1224975, episodes: 49000, mean episode reward: -9.740704562075607, agent episode reward: [-1.957608613942606, -7.783095948133001], time: 52.304
maddpg vs maddpg steps: 1249975, episodes: 50000, mean episode reward: -9.682697604942707, agent episode reward: [-2.136866636684718, -7.545830968257988], time: 51.341
maddpg vs maddpg steps: 1274975, episodes: 51000, mean episode reward: -9.923191849194808, agent episode reward: [-1.915672386135644, -8.007519463059163], time: 52.074
maddpg vs maddpg steps: 1299975, episodes: 52000, mean episode reward: -9.52933123998819, agent episode reward: [-1.4216450709393809, -8.10768616904881], time: 51.567
maddpg vs maddpg steps: 1324975, episodes: 53000, mean episode reward: -10.00970611779495, agent episode reward: [-1.8435836109372536, -8.166122506857697], time: 52.018
maddpg vs maddpg steps: 1349975, episodes: 54000, mean episode reward: -9.577982285437935, agent episode reward: [-2.2884268262056073, -7.289555459232328], time: 51.222
maddpg vs maddpg steps: 1374975, episodes: 55000, mean episode reward: -10.324927666026927, agent episode reward: [-2.760582307487997, -7.564345358538929], time: 52.512
maddpg vs maddpg steps: 1399975, episodes: 56000, mean episode reward: -10.11267984575088, agent episode reward: [-2.8846310023028643, -7.228048843448017], time: 49.604
maddpg vs maddpg steps: 1424975, episodes: 57000, mean episode reward: -10.471501197617572, agent episode reward: [-3.152323571022646, -7.319177626594927], time: 47.248
maddpg vs maddpg steps: 1449975, episodes: 58000, mean episode reward: -10.184889585985529, agent episode reward: [-2.8020686637700347, -7.382820922215495], time: 46.638
maddpg vs maddpg steps: 1474975, episodes: 59000, mean episode reward: -10.49379714696094, agent episode reward: [-3.307427991773581, -7.186369155187359], time: 45.849
maddpg vs maddpg steps: 1499975, episodes: 60000, mean episode reward: -10.21094100212562, agent episode reward: [-2.9945582316794486, -7.216382770446173], time: 47.057
...Finished total of 60001 episodes.
