0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -33.05127272977027, agent episode reward: [0.5677585114754454, 0.5620712675862646, 0.5761578813021354, 0.5097672563290616, -14.211833971099441, -21.05519367536374], time: 249.9
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -16.268981217634124, agent episode reward: [2.5629793616038334, 2.654562633241453, 2.749472603976799, 3.0575541162952717, -16.074091107135217, -11.219458825616268], time: 320.573
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 11.281008430165526, agent episode reward: [3.9496208872206187, 3.7818877870327934, 3.760857327553584, 4.291804169413784, -2.695706639986341, -1.807455101068911], time: 324.578
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 10.358729156023822, agent episode reward: [3.5226142745090265, 3.555354936633109, 3.223248936571733, 3.9356569052627535, -2.0853280903860414, -1.7928178065667593], time: 328.444
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 15.426354389400657, agent episode reward: [5.142883282268334, 5.106565901900294, 5.163812398626829, 5.416716772906695, -2.9005877548742336, -2.503036211427263], time: 329.291
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 18.201798584139965, agent episode reward: [5.713273394512882, 5.7677294428561305, 6.077313039287421, 6.309309029080385, -2.7288431234206554, -2.9369831981762027], time: 329.189
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 20.579623998908776, agent episode reward: [6.633524922912891, 6.561748486451799, 6.833573214164816, 6.887064766593081, -3.0844027142016666, -3.2518846770121477], time: 328.425
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 22.782606007552694, agent episode reward: [7.592624240721864, 7.342603649854207, 7.481397415699215, 7.596642527649026, -3.4043644079162716, -3.8262974184553458], time: 329.117
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 23.354339451330468, agent episode reward: [7.819736906729315, 7.7222478669860015, 7.747701742288296, 7.718057059944249, -3.97047928581286, -3.6829248388045324], time: 332.011
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 25.915857547341975, agent episode reward: [8.705997897501199, 8.648158399580323, 8.831464787325503, 8.692282101826477, -4.660580554892597, -4.301465083998927], time: 328.95
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 27.267254838806526, agent episode reward: [9.01328063302373, 9.02484950627165, 9.158039714987916, 8.941805229904404, -4.23937848098342, -4.631341764397752], time: 330.565
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 28.512055519388987, agent episode reward: [9.322291557975268, 9.29655788089608, 9.461065176783425, 9.241969372545187, -4.829082445101652, -3.980746023709321], time: 332.875
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 31.29441944313713, agent episode reward: [10.232839995082559, 10.204746958746325, 10.275586864155368, 10.117663812338042, -5.662665521551719, -3.8737526656334453], time: 330.426
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 40.31385991773799, agent episode reward: [13.257273648937105, 13.019023944083267, 13.212700848083168, 13.056317984369247, -6.07316618117136, -6.158290326563431], time: 332.181
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 37.387241765957306, agent episode reward: [12.299710069656593, 12.151821889256011, 12.268133711560925, 12.162215515054399, -5.43368125693174, -6.060958162638877], time: 329.106
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 40.55361005027269, agent episode reward: [13.328084143896213, 13.12902010579023, 13.263227368165735, 13.236142984780688, -5.861571615530311, -6.541292936829866], time: 332.015
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 42.57241946303721, agent episode reward: [14.05016925170456, 13.862573029951724, 13.995736777231661, 13.963073227395322, -7.857243883012488, -5.44188894023357], time: 330.738
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 39.95128768515028, agent episode reward: [13.299276318252183, 13.01181615835984, 13.17529169721344, 13.214764856357778, -7.3182265137012035, -5.431634831331768], time: 331.622
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 36.25916399429071, agent episode reward: [12.007429461332974, 11.82820208953461, 11.970449273691974, 11.959363507317539, -5.161518447949085, -6.344761889637301], time: 330.483
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 33.37960455001756, agent episode reward: [11.182186779458862, 11.069045429790213, 11.155403223260084, 11.184482677811799, -5.364035205798367, -5.847478354505027], time: 331.613
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 29.571217897130776, agent episode reward: [9.958482605098457, 9.807243827779434, 10.021285663622725, 9.985008267051434, -4.5606479064135765, -5.640154560007699], time: 332.989
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 33.07918241957552, agent episode reward: [11.042928064820476, 10.899038513107563, 11.036093844896437, 11.009880174741495, -4.640042635103611, -6.268715542886847], time: 330.722
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 28.902325675172776, agent episode reward: [9.822935646747387, 9.56112500193417, 9.87496031834231, 9.705276475419781, -5.175561446247111, -4.886410321023764], time: 331.288
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 29.471557625344584, agent episode reward: [10.312306958435343, 10.153937039345386, 10.289799250148159, 10.139838845669084, -5.7055974801013765, -5.718726988152013], time: 329.374
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 26.161017047899698, agent episode reward: [9.159697143888007, 8.99027414689344, 9.132352899911787, 8.97273608190069, -4.739958999886243, -5.354084224807983], time: 328.276
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 20.8843819712621, agent episode reward: [7.948868295683929, 7.849783553155538, 7.990797576965339, 7.811268874923386, -5.5331625620290374, -5.1831737674370535], time: 327.995
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 22.334184849303842, agent episode reward: [8.379398778089552, 8.309994869322221, 8.45184450391983, 8.204458548751608, -5.631969861944427, -5.379541988834941], time: 328.289
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 19.367530735915867, agent episode reward: [7.596511542581984, 7.488029401759608, 7.63248407884996, 7.379112210891257, -5.402703956832148, -5.325902541334791], time: 324.183
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 17.919029589599216, agent episode reward: [7.65780004119232, 7.562713036362918, 7.677427870666967, 7.359310963792332, -5.884761401996917, -6.4534609204184], time: 321.095
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 21.02019754054246, agent episode reward: [8.44568960803354, 8.398210316421943, 8.46860416822946, 8.10385028451223, -6.2568804109699805, -6.139276425684732], time: 320.319
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 17.70951584073151, agent episode reward: [7.412033239841034, 7.342806883026541, 7.439384791358736, 7.207046824454586, -6.096664950091317, -5.595090947858067], time: 319.218
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 16.74490431965212, agent episode reward: [7.550096182969725, 7.402720588032665, 7.630014665635979, 7.3468214931461535, -7.388425913526171, -5.796322696606226], time: 319.227
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 19.94865974364693, agent episode reward: [8.354757399803592, 8.272759925629256, 8.433629777101402, 8.16924745145722, -7.196400430313178, -6.08533438003136], time: 320.913
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 19.09193803920831, agent episode reward: [8.03058774186377, 7.947355256016615, 7.973969346949208, 7.817150864474693, -6.589470119018361, -6.087655051077621], time: 318.9
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 22.536358449429027, agent episode reward: [9.184096795231, 9.079557700214083, 9.129943326671494, 9.020345896525242, -6.578372297034083, -7.299212972178707], time: 319.265
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 26.060380120998417, agent episode reward: [9.781518898367501, 9.676249296466128, 9.728882187008407, 9.574889085590241, -4.8725081463696895, -7.828651200064171], time: 322.709
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 27.537638091516072, agent episode reward: [9.828797552734512, 9.571384434845402, 9.662202266078467, 9.6148758939088, -3.9335745975394922, -7.206047458511614], time: 318.184
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 26.816622309578563, agent episode reward: [9.374332088239727, 9.090546717291753, 9.100558466330195, 9.216864926555237, -3.2979172852164957, -6.667762603621857], time: 319.459
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 30.039830434409456, agent episode reward: [10.381012095635382, 10.245812794818077, 10.15806533033005, 10.215892386444033, -3.892480805028528, -7.068471367789559], time: 318.918
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 26.277671755455508, agent episode reward: [9.403029553204414, 9.078453499029814, 9.086873994973706, 9.161802423034198, -3.697246956919205, -6.755240757867422], time: 317.829
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 27.397545520262508, agent episode reward: [9.682455206364796, 9.471897442838669, 9.473769940194924, 9.402264976199028, -4.621304354223509, -6.011537691111396], time: 316.086
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 24.83171487628888, agent episode reward: [9.236647508070938, 8.940406760833062, 8.858102563887206, 8.85030806623738, -3.7545016960828836, -7.299248326656817], time: 317.545
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 24.265075470840774, agent episode reward: [9.457820111696295, 9.058204086866496, 9.05320851077778, 8.99336192128824, -4.562548903665926, -7.734970256122113], time: 316.889
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 21.769707141797525, agent episode reward: [8.549501549928435, 8.18499856588025, 8.258533510367965, 8.007176534746948, -3.3094871182304595, -7.921015900895616], time: 319.422
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 22.539218233868358, agent episode reward: [8.481124769790343, 8.002953524234101, 8.218342260681224, 7.9822540993716755, -3.7453636588986794, -6.4000927613103125], time: 319.762
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 24.421589563481334, agent episode reward: [9.013016309752533, 8.751193275679173, 8.86215758642037, 8.578603890514144, -3.0879189704766743, -7.695462528408212], time: 319.959
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 23.656373845141978, agent episode reward: [8.866542900500905, 8.484805805367232, 8.606124015574114, 8.404024398799775, -3.474813364363311, -7.230309910736738], time: 318.352
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 21.49471232234076, agent episode reward: [8.340695873469635, 8.029366287002562, 8.085143244509931, 7.897952870082021, -3.6373296776232293, -7.221116275100155], time: 318.383
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 23.24082801159724, agent episode reward: [8.912426261661782, 8.603521981632454, 8.791390426629285, 8.47410679440207, -4.333616859789586, -7.207000592938763], time: 320.285
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 24.255151902493104, agent episode reward: [9.287458736201305, 9.0854873974101, 9.232611682755204, 8.958652360456272, -3.742695884315496, -8.56636239001428], time: 316.325
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 25.892441249547016, agent episode reward: [8.978090323712877, 8.898150097252191, 8.904788747646212, 8.830854012154735, -3.671636291602591, -6.047805639616403], time: 317.643
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 22.96447787365003, agent episode reward: [8.503681664253909, 8.105768247379292, 8.206202861109709, 8.040840312496186, -2.8651326684082976, -7.026882543180769], time: 316.586
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 22.854413733019072, agent episode reward: [8.292664703887342, 8.140462830409428, 8.20081600206934, 8.056458895654847, -3.0811447892263977, -6.754843909775486], time: 317.097
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 25.989853076020477, agent episode reward: [9.482008050133752, 9.216270719259427, 9.388616361026552, 9.179287523222715, -4.396535690090475, -6.879793887531492], time: 315.597
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 30.027694075764266, agent episode reward: [10.83407739484185, 10.491577751690965, 10.664263777735753, 10.49807971124465, -5.1535814932150465, -7.306723066533903], time: 314.364
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 29.69223062666697, agent episode reward: [10.561096400321274, 10.140596763638566, 10.43610226543596, 10.291664933843611, -4.8534800178582165, -6.883749718714225], time: 318.267
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 27.23258574887352, agent episode reward: [9.502442814517241, 9.162420673292575, 9.226489447304346, 9.346077958999238, -3.804260285026747, -6.200584860213134], time: 314.693
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 27.72077954314673, agent episode reward: [9.910150594009965, 9.541013889069523, 9.67860981366771, 9.704804499316127, -4.752996136500944, -6.360803116415647], time: 317.381
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 33.103680158200014, agent episode reward: [11.511512577334491, 11.204722457343069, 11.324163054393212, 11.349597571753565, -5.308801475157719, -6.977514027466606], time: 315.765
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 34.99200240700982, agent episode reward: [11.86336621979354, 11.690756596363189, 11.821044848459529, 11.838592409163153, -5.906593362896734, -6.3151643038728515], time: 260.936
...Finished total of 60001 episodes.
