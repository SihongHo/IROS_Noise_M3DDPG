0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 0.001]
3 good agents
      adv rate for q_index :  3 [0.001, 0.001, 0.001, 1e-05]
      adv rate for p_index :  3 [0.001, 0.001, 0.001, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 3 adversaries
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -1.2247372342402114, agent episode reward: [2.53, 2.53, 2.53, -8.814737234240212], time: 108.613
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -10.200553548412225, agent episode reward: [3.5, 3.5, 3.5, -20.700553548412223], time: 157.699
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 6.3657918224151215, agent episode reward: [4.37, 4.37, 4.37, -6.744208177584877], time: 155.04
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 8.74716795231084, agent episode reward: [4.75, 4.75, 4.75, -5.502832047689161], time: 154.634
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 10.613877943770005, agent episode reward: [5.79, 5.79, 5.79, -6.756122056229994], time: 156.199
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 16.88674332438829, agent episode reward: [8.81, 8.81, 8.81, -9.543256675611707], time: 154.579
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 29.17441211799071, agent episode reward: [15.18, 15.18, 15.18, -16.365587882009287], time: 156.36
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 34.6453487085256, agent episode reward: [17.88, 17.88, 17.88, -18.994651291474394], time: 156.569
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 26.148855127906618, agent episode reward: [13.73, 13.73, 13.73, -15.041144872093376], time: 156.465
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 14.85306499234022, agent episode reward: [8.81, 8.81, 8.81, -11.576935007659781], time: 155.856
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 18.01669357481053, agent episode reward: [10.73, 10.73, 10.73, -14.17330642518947], time: 155.935
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 38.707095728459755, agent episode reward: [21.19, 21.19, 21.19, -24.862904271540252], time: 156.062
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 55.93000210505637, agent episode reward: [29.5, 29.5, 29.5, -32.56999789494363], time: 155.879
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 52.24319357686101, agent episode reward: [27.67, 27.67, 27.67, -30.76680642313899], time: 156.664
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 36.37140587538142, agent episode reward: [20.26, 20.26, 20.26, -24.40859412461858], time: 158.791
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 24.72219488661521, agent episode reward: [14.78, 14.78, 14.78, -19.61780511338479], time: 163.135
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 10.968899436861152, agent episode reward: [9.54, 9.54, 9.54, -17.651100563138847], time: 164.014
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 8.678828885165956, agent episode reward: [8.35, 8.35, 8.35, -16.371171114834045], time: 164.459
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 8.91047140420779, agent episode reward: [8.38, 8.38, 8.38, -16.229528595792207], time: 164.369
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 3.4426251718688, agent episode reward: [5.32, 5.32, 5.32, -12.5173748281312], time: 164.348
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 2.472833433294397, agent episode reward: [4.66, 4.66, 4.66, -11.507166566705605], time: 165.143
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 4.1122422125441656, agent episode reward: [5.09, 5.09, 5.09, -11.157757787455834], time: 165.282
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 4.141852881177031, agent episode reward: [4.98, 4.98, 4.98, -10.798147118822968], time: 165.005
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 6.942417289381337, agent episode reward: [5.96, 5.96, 5.96, -10.937582710618665], time: 165.135
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 7.600099937587058, agent episode reward: [6.2, 6.2, 6.2, -10.99990006241294], time: 164.843
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 10.174483476281646, agent episode reward: [7.15, 7.15, 7.15, -11.275516523718352], time: 165.007
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 14.1296625551468, agent episode reward: [9.05, 9.05, 9.05, -13.020337444853203], time: 165.427
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 15.459794071146698, agent episode reward: [9.62, 9.62, 9.62, -13.400205928853302], time: 166.013
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 14.11485323980715, agent episode reward: [9.07, 9.07, 9.07, -13.095146760192849], time: 165.568
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 17.907494300194102, agent episode reward: [10.84, 10.84, 10.84, -14.612505699805897], time: 163.84
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 18.37264317406211, agent episode reward: [11.29, 11.29, 11.29, -15.49735682593789], time: 165.228
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 16.14814701312403, agent episode reward: [10.19, 10.19, 10.19, -14.421852986875969], time: 163.774
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 16.02143059120673, agent episode reward: [9.98, 9.98, 9.98, -13.918569408793267], time: 163.803
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 20.94066998734164, agent episode reward: [11.87, 11.87, 11.87, -14.66933001265836], time: 165.174
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 16.74072836788362, agent episode reward: [9.7, 9.7, 9.7, -12.359271632116378], time: 164.975
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 19.231645724063483, agent episode reward: [11.0, 11.0, 11.0, -13.768354275936515], time: 165.763
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 16.794283132158807, agent episode reward: [9.98, 9.98, 9.98, -13.145716867841195], time: 164.536
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 19.40084507955425, agent episode reward: [10.88, 10.88, 10.88, -13.239154920445749], time: 163.433
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 17.552648546953066, agent episode reward: [10.13, 10.13, 10.13, -12.837351453046933], time: 165.474
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 19.150986229753048, agent episode reward: [10.78, 10.78, 10.78, -13.189013770246948], time: 163.86
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 21.72233593888684, agent episode reward: [12.1, 12.1, 12.1, -14.577664061113158], time: 164.34
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 16.35908722867015, agent episode reward: [9.77, 9.77, 9.77, -12.95091277132985], time: 163.243
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 17.48224229205364, agent episode reward: [10.15, 10.15, 10.15, -12.967757707946358], time: 165.439
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 20.015928832245272, agent episode reward: [11.42, 11.42, 11.42, -14.244071167754726], time: 164.319
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 19.36652651120888, agent episode reward: [10.81, 10.81, 10.81, -13.063473488791121], time: 165.024
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 18.96046847861274, agent episode reward: [10.46, 10.46, 10.46, -12.419531521387258], time: 165.033
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 16.21599063363057, agent episode reward: [9.4, 9.4, 9.4, -11.984009366369428], time: 165.236
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 16.388184163432836, agent episode reward: [9.34, 9.34, 9.34, -11.631815836567162], time: 165.525
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 15.198297624408228, agent episode reward: [8.88, 8.88, 8.88, -11.44170237559177], time: 165.146
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 13.658783993403464, agent episode reward: [7.98, 7.98, 7.98, -10.281216006596535], time: 165.532
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 16.732806269814724, agent episode reward: [9.51, 9.51, 9.51, -11.797193730185278], time: 163.454
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 17.958257161395203, agent episode reward: [9.98, 9.98, 9.98, -11.981742838604799], time: 165.445
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 16.867537551066686, agent episode reward: [9.49, 9.49, 9.49, -11.602462448933315], time: 164.534
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 15.460067642331447, agent episode reward: [8.73, 8.73, 8.73, -10.729932357668552], time: 165.773
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 16.666094249380638, agent episode reward: [9.36, 9.36, 9.36, -11.41390575061936], time: 166.284
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 18.679027115889223, agent episode reward: [10.68, 10.68, 10.68, -13.360972884110776], time: 163.353
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 19.463497838181745, agent episode reward: [10.63, 10.63, 10.63, -12.426502161818252], time: 156.027
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 19.68589000827671, agent episode reward: [10.82, 10.82, 10.82, -12.774109991723286], time: 156.114
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 19.99321493045456, agent episode reward: [11.01, 11.01, 11.01, -13.03678506954544], time: 150.708
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 26.050702252044736, agent episode reward: [14.3, 14.3, 14.3, -16.849297747955266], time: 151.601
...Finished total of 60001 episodes.
