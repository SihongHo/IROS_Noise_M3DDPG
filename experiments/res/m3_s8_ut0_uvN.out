0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -21.55939103252439, agent episode reward: [1.1863530496491812, 1.1120208031340744, 1.1473311183811592, 1.0920150280357142, -10.179051724159482, -15.918059307565036], time: 216.605
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -14.743388281754607, agent episode reward: [3.0317220646260816, 3.132808763260676, 2.6529345357070473, 2.95204052165991, -8.511232999591531, -18.001661167416792], time: 276.842
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 12.837098372704506, agent episode reward: [4.535489729897612, 4.255163872260856, 4.278152644974676, 4.308279333854017, -2.2436987955615013, -2.2962884127211542], time: 273.86
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 16.208799624293384, agent episode reward: [5.503429630524832, 5.189919395250966, 5.658425815938665, 5.221619143447006, -2.4980290058905013, -2.866565354977585], time: 273.784
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 21.632039264376022, agent episode reward: [7.194668821456645, 6.748589465801513, 7.212323308306493, 7.2879765450064715, -3.3321893182208933, -3.4793295579742067], time: 273.775
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 23.646484490236297, agent episode reward: [7.650196908126647, 7.332785007003619, 7.8417587876396, 7.910432649802777, -3.1205236803223744, -3.968165182013975], time: 273.827
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 32.86021079746804, agent episode reward: [10.846395032461325, 10.350547840551931, 10.931547402653067, 11.073547472368391, -4.582662429651965, -5.75916452091471], time: 274.507
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 40.0270309516955, agent episode reward: [13.132790137604719, 12.786434467274335, 13.029534035967975, 13.147420355301398, -5.86351724270434, -6.205630801748591], time: 273.672
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 45.43542091045614, agent episode reward: [15.033904561474822, 14.95427072723407, 14.865074344173616, 15.029735716638355, -7.408614557171199, -7.038949881893528], time: 276.286
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 43.75037051364294, agent episode reward: [14.41177681629829, 14.29280296860605, 14.288349138679463, 14.474325258739977, -7.693424821845264, -6.023458846835574], time: 273.601
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 37.26367405841715, agent episode reward: [12.342454526492977, 12.213268722864775, 12.277194121938722, 12.363992642855871, -6.949593274197662, -4.9836426815375345], time: 274.46
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 44.605836202980385, agent episode reward: [14.686311183149654, 14.599348661411367, 14.601406203960849, 14.633079342396304, -7.614982055549992, -6.2993271323878], time: 275.417
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 37.77014380781665, agent episode reward: [12.444205890729378, 12.402353311981576, 12.409396234427046, 12.381462101990968, -6.6433402259830245, -5.223933505329286], time: 273.295
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 32.93998703717471, agent episode reward: [11.077018432623907, 11.096184679304658, 11.081507504091645, 11.020392084412372, -6.441185660988759, -4.893930002269114], time: 276.727
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 23.888617482291913, agent episode reward: [8.440769399494544, 8.427728045183539, 8.427390612221775, 8.388973039220906, -4.874220039791833, -4.922023574037021], time: 273.709
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 22.692017422394603, agent episode reward: [7.890013944314682, 7.873741251974112, 7.829057634427983, 7.837484775898906, -4.512079904443846, -4.226200279777231], time: 274.887
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 19.603458197576423, agent episode reward: [6.911189530559653, 6.963916953408588, 6.915917722801636, 6.933320945164756, -4.284587342084681, -3.8362996122735322], time: 273.712
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 17.653026780038953, agent episode reward: [6.3935846208877685, 6.393629433444517, 6.377806344869361, 6.408000810318049, -4.405589656069911, -3.5144047734108312], time: 274.853
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 19.913213081523004, agent episode reward: [6.904577074922008, 6.961709329746282, 6.936671124561327, 6.901588904814513, -4.639258489173558, -3.152074863347564], time: 274.758
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 19.592777207981456, agent episode reward: [6.800755496864388, 6.793390474743031, 6.760294398092794, 6.705669444262822, -3.8350664348169157, -3.6322661711646616], time: 272.019
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 20.152931746446455, agent episode reward: [7.094966148797148, 7.080333330577859, 7.036712955356274, 6.92917406629502, -3.6096237988393534, -4.378630955740491], time: 272.888
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 18.36802741706138, agent episode reward: [6.511235786421464, 6.4799534879237655, 6.4060281240000325, 6.383253816767918, -3.2358616034329746, -4.176582194618824], time: 273.723
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 17.77288780829849, agent episode reward: [6.2056784022029445, 6.1524121925181845, 6.149051457706351, 6.0303427874426925, -3.08259662469747, -3.682000406874212], time: 273.643
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 22.828072438925883, agent episode reward: [7.617655717472994, 7.501500975038245, 7.462938094944499, 7.3923831270225575, -3.106691429096365, -4.039714046456047], time: 272.995
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 23.993437660918122, agent episode reward: [8.132962521629686, 7.97232669788272, 8.012438157165704, 7.91507324437223, -3.7282279253242705, -4.311135034807945], time: 273.363
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 22.93300186910102, agent episode reward: [7.790886497401614, 7.633783402382235, 7.6513732849457154, 7.513028658404107, -3.1462879041116016, -4.509782069921046], time: 272.769
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 26.24415166358453, agent episode reward: [8.714046711131942, 8.636836531746864, 8.647900881030154, 8.467754669579929, -3.2176294780240426, -5.00475765188031], time: 272.688
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 22.200233260770613, agent episode reward: [7.443809930004339, 7.395033683721267, 7.282647234447976, 7.201220589499329, -3.01339407105799, -4.10908410584431], time: 271.625
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 23.317657382643628, agent episode reward: [7.925511026390134, 7.8201614384783875, 7.628095456944421, 7.697317799465651, -3.6457123366313997, -4.107716002003567], time: 268.648
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 19.89787112757151, agent episode reward: [6.672364273835187, 6.75127516870892, 6.235590733542385, 6.60100283719306, -3.2563490650936666, -3.1060128206143753], time: 269.453
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 20.334559453883646, agent episode reward: [6.888207486973312, 6.902840100021568, 6.469194522824376, 6.756274984004407, -3.5145352790180997, -3.167422360921918], time: 267.849
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 21.637344409938656, agent episode reward: [7.331915037009948, 7.3694953733316835, 6.970745520484605, 7.193609667506143, -3.6099484886262934, -3.6184726997674335], time: 269.994
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 22.01847652424162, agent episode reward: [7.575896595958304, 7.55661745832254, 6.991058704392294, 7.436518295810341, -3.9658996429451516, -3.575714887296706], time: 267.861
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 23.628234136873594, agent episode reward: [8.127337843969723, 8.069798705537359, 7.596291559778468, 7.973265902239298, -4.388523204282365, -3.7499366703688892], time: 263.113
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 25.25748526978572, agent episode reward: [8.524283245635722, 8.525691107294048, 8.047361579559448, 8.398524863622614, -4.28300179625384, -3.955373730072272], time: 266.884
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 24.081468338033897, agent episode reward: [8.12435919214856, 8.073372998620652, 7.726886110546182, 8.026412969695198, -3.858959441419543, -4.0106034915571485], time: 265.737
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 24.245328927878937, agent episode reward: [8.167286879998098, 8.041667269462758, 7.852676746919131, 8.064814373738054, -3.8333996989826438, -4.04771664325646], time: 265.097
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 25.67631083398415, agent episode reward: [8.591861923699962, 8.548444479383681, 8.350558752664357, 8.544889605536502, -3.942057019153325, -4.417386908147033], time: 265.701
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 26.791001217933474, agent episode reward: [8.862347965062458, 8.80420681311594, 8.725413239030091, 8.916537417294423, -3.9071221929101103, -4.610382023659329], time: 263.81
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 28.630447339363137, agent episode reward: [9.518755282330199, 9.59012293136112, 9.453521461222032, 9.603455851913017, -4.481686791593327, -5.053721395869901], time: 262.121
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 27.283537699180496, agent episode reward: [9.042022306816342, 9.158052892126788, 9.065113461253738, 9.25302479400755, -4.398828006081911, -4.83584774894201], time: 265.358
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 29.773452602088785, agent episode reward: [9.855694428189487, 9.997683820609582, 9.943672192336708, 10.026766419515578, -5.330774312892282, -4.719589945670285], time: 262.978
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 33.54349470428153, agent episode reward: [11.230807868398196, 11.370829499726613, 11.242858878208327, 11.34911621357769, -6.103312675071357, -5.546805080557946], time: 265.723
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 30.96381577696231, agent episode reward: [10.192392000491425, 10.439583233249497, 10.374004396346965, 10.342105836416202, -5.260876141127961, -5.123393548413818], time: 262.278
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 29.259083103666498, agent episode reward: [9.699992494895913, 9.845443274021077, 9.695083539355132, 9.657621144377993, -5.532112307151298, -4.106945041832323], time: 261.879
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 26.10270944772076, agent episode reward: [9.19224751548706, 9.199819574633738, 9.123040539383824, 9.04474162018892, -6.602846710235567, -3.854293091737216], time: 261.778
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 22.29593272766852, agent episode reward: [7.882420345734146, 7.853314785376147, 7.72097975505032, 7.7346602455935765, -5.037527519170592, -3.8579148849150826], time: 266.579
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 18.35026544992515, agent episode reward: [6.685285436496059, 6.650946591154241, 6.309520096383711, 6.44864399096914, -4.578283029557104, -3.1658476355208967], time: 262.798
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 17.87278332127397, agent episode reward: [6.411217129542434, 6.2774111549064955, 5.9651341727304015, 6.118268400813262, -4.044472983092843, -2.8547745536257767], time: 265.238
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 19.144091824547154, agent episode reward: [6.682027751848008, 6.4047434333245095, 6.426676844643898, 6.421030543662269, -3.558827103545675, -3.231559645385858], time: 264.029
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 19.834300429963683, agent episode reward: [6.921762659814627, 6.778088100903821, 6.728278187986963, 6.73158389801457, -4.4086108658052305, -2.9168015509510696], time: 262.86
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 20.282712005935295, agent episode reward: [7.140718930506126, 6.921093793116072, 6.999111070517753, 6.925748120642902, -4.019671847850805, -3.6842880609967525], time: 260.598
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 20.354845147847197, agent episode reward: [7.270211303333055, 6.990265297707482, 7.153189794445164, 7.025650194717769, -4.511642887628188, -3.572828554728084], time: 261.033
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 18.711144362817315, agent episode reward: [6.854882705003641, 6.561031061691852, 6.752777480500893, 6.648099059074047, -4.705242810915109, -3.400403132538012], time: 263.24
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 18.585466318459016, agent episode reward: [6.8011219200147774, 6.490879312561313, 6.654285318594814, 6.569153152293135, -4.11701099073762, -3.8129623942674025], time: 263.6
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 19.905242635843525, agent episode reward: [7.222386207324783, 6.8790563741318485, 7.134921456638505, 6.908859459099144, -4.231248089041409, -4.008732772309347], time: 261.926
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 20.170471998881478, agent episode reward: [7.1619542145404855, 6.780390040083351, 6.9853807445332405, 6.905465258506551, -3.2377403294933993, -4.424977929288751], time: 266.373
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 21.32020188062728, agent episode reward: [7.754030299356167, 7.370979015323009, 7.550656978293757, 7.451213159586868, -4.0776242834030265, -4.729053288529496], time: 260.894
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 23.27517395665613, agent episode reward: [8.5287371331581, 8.186390605570933, 8.353395022023404, 8.330172839035681, -4.540700669726824, -5.582820973405164], time: 234.238
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 23.84853743121541, agent episode reward: [8.767810641789552, 8.511948055198513, 8.527217790682702, 8.485724136421322, -5.081337212454108, -5.362825980422569], time: 206.748
...Finished total of 60001 episodes.
