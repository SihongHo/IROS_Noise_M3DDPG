0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Uncertainty type is:  None ; Uncertainty level is:  1.0
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -20.45471957216901, agent episode reward: [1.4311951593662018, 1.3874292433911937, 1.3555224503981838, 1.4162723396210002, -12.776637257074533, -13.268501507871058], time: 218.798
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -13.114971738523636, agent episode reward: [3.118772221387467, 3.105363704600804, 2.633265368532686, 2.563168437972735, -13.660974538324721, -10.874566932692602], time: 277.146
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 15.434863313978939, agent episode reward: [4.912368026959939, 5.7105366462744716, 5.1062251578843485, 5.238433734074539, -3.149027634223542, -2.383672616990818], time: 273.745
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 18.232212611403927, agent episode reward: [5.7575741205557405, 6.301642213719273, 5.809871391259424, 5.880685536929135, -2.5584624205988664, -2.9590982304607816], time: 274.569
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 25.13155513969805, agent episode reward: [8.192034894539194, 8.386477679600812, 8.085772081342554, 8.136758764909864, -3.5417399703573436, -4.1277483103370285], time: 273.854
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 24.606384451106404, agent episode reward: [8.249300215568718, 8.323093205607638, 8.17796169155199, 8.135789473279898, -4.347104038993836, -3.9326560959080075], time: 273.425
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 26.00091737888401, agent episode reward: [8.978781575268917, 8.99387766556081, 8.5805960541286, 8.73870004665594, -4.27823842360966, -5.01279953912059], time: 274.112
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 30.77619108152944, agent episode reward: [10.332266950532679, 10.269854052432557, 10.06539179103537, 10.12272642621618, -4.655605714930716, -5.358442423756632], time: 273.834
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 33.00647547561828, agent episode reward: [11.106765837324176, 11.077802210718488, 10.874165406278877, 10.904673763400009, -5.252022708927837, -5.704909033175438], time: 273.221
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 35.863148071859946, agent episode reward: [12.048269790089915, 11.946214011445091, 11.815498842547186, 11.846326324688555, -5.613300263460919, -6.179860633449889], time: 274.527
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 35.40230277765016, agent episode reward: [11.859406422668814, 11.82176259640209, 11.569310689901496, 11.59572773089397, -5.826948381236534, -5.6169562809796725], time: 275.834
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 28.174370235194147, agent episode reward: [9.80847258741295, 9.8136466659636, 9.583674953091776, 9.658267414240745, -5.3988749325720615, -5.290816452942863], time: 274.224
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 29.55627875822819, agent episode reward: [10.139166080211659, 10.156448287492218, 9.890230612278366, 10.064065941919893, -6.109046463095967, -4.584585700577977], time: 275.441
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 27.497611347200987, agent episode reward: [9.46517292200926, 9.464926550691327, 9.157403690326806, 9.369556429356992, -5.431331861541818, -4.528116383641578], time: 272.745
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 26.53551539448349, agent episode reward: [9.332584635745668, 9.308712037186142, 8.96943451199598, 9.234194588388293, -5.433654423643736, -4.875755955188856], time: 274.111
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 25.888358454081924, agent episode reward: [8.934029534191856, 8.892599871919417, 8.63685521173075, 8.812978039396464, -6.064074899883319, -3.3240293032732473], time: 273.82
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 24.4039957028509, agent episode reward: [8.451616913094009, 8.380657438792813, 8.059425646705325, 8.31718604260578, -5.049008202038426, -3.7558821363086046], time: 273.201
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 27.5892422212945, agent episode reward: [9.385839510849769, 9.333218053946783, 8.949877270123839, 9.324327369913513, -6.300130548280659, -3.1038894352587496], time: 274.315
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 26.927462505448844, agent episode reward: [9.050518800526334, 8.955197195976744, 8.687623355556337, 8.985827244716292, -5.497709752037621, -3.2539943392892456], time: 273.39
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 27.970711880881705, agent episode reward: [9.474337722413853, 9.267745288161777, 9.067187163156417, 9.45661192080536, -5.756748768687261, -3.5384214449684377], time: 273.647
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 27.21711232428797, agent episode reward: [9.325758339937181, 9.150132309532056, 8.845123804003906, 9.35041564632878, -6.124485670696695, -3.3298321048172546], time: 272.497
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 26.59964470929404, agent episode reward: [9.388932168284184, 9.229468656140849, 8.90231984751934, 9.391301741313043, -6.8445838836861, -3.4677938202772762], time: 273.541
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 29.828642219920916, agent episode reward: [10.232222930791716, 10.080021665578716, 9.868712805163831, 10.249443115683656, -6.989301956110093, -3.6124563411869115], time: 272.945
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 30.294548038012703, agent episode reward: [10.279258277592781, 10.126360197500398, 9.924451871296572, 10.328895040429218, -6.861209621066356, -3.503207727739911], time: 273.794
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 29.377935232681825, agent episode reward: [10.185728318024518, 10.002412451759245, 9.90728207187627, 10.177780959324867, -6.935770947139492, -3.9594976211635835], time: 272.687
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 23.602043523927932, agent episode reward: [8.46695693881938, 8.29834341586178, 8.220805761614159, 8.333503204756806, -6.549615526693849, -3.1679502704303415], time: 273.26
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 25.684835162451325, agent episode reward: [8.962734134809041, 8.722620316910396, 8.69658236024176, 8.702769057311134, -5.771523521167323, -3.6283471856536815], time: 272.921
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 23.308437425350455, agent episode reward: [8.37555216000083, 8.171435956522261, 8.214960760623908, 8.2811669361354, -6.314743334920066, -3.4199350530118764], time: 272.113
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 23.635997064803142, agent episode reward: [8.552334518558535, 8.401294249230311, 8.349512144188878, 8.410241697517183, -6.201382276580684, -3.876003268111087], time: 269.173
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 25.07819071387225, agent episode reward: [8.776718937803102, 8.635433944140427, 8.508158214585551, 8.639726015668135, -6.039865148295378, -3.4419812500295865], time: 268.425
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 24.323484823080108, agent episode reward: [8.579383280760501, 8.497450012386155, 8.422249746840698, 8.596145840619247, -5.913401610735806, -3.858342446790686], time: 268.743
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 23.91176934203769, agent episode reward: [8.501048971817287, 8.286940823744123, 8.368386522389294, 8.517652962860199, -6.148678402362625, -3.613581536410588], time: 269.106
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 24.56067239131901, agent episode reward: [8.545182654476926, 8.37193814962373, 8.408854591236077, 8.600077345166834, -5.9291751089058655, -3.436205240278695], time: 265.047
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 25.17908576566667, agent episode reward: [8.814319457757344, 8.627366497014588, 8.740403276643802, 8.966016950389717, -6.557298636773466, -3.411721779365311], time: 264.544
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 25.199518858957116, agent episode reward: [8.656282438467045, 8.348268347630354, 8.629314340161633, 8.799193579592435, -5.731496572703211, -3.5020432741911427], time: 266.061
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 28.33978675501624, agent episode reward: [9.924682142433342, 9.451174447072685, 9.664717309267575, 9.913532897210137, -5.946987022489635, -4.667333018477864], time: 265.874
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 29.931616680156324, agent episode reward: [10.328755399488502, 9.759495763535593, 10.03275626592013, 10.201751371246045, -5.2056611647631605, -5.185480955270787], time: 266.253
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 33.48385646746361, agent episode reward: [11.509634568972167, 10.935936672321239, 11.178965776977467, 11.35447764145835, -5.705110704667673, -5.790047487597942], time: 264.453
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 32.84869235179371, agent episode reward: [11.378478212252583, 10.920792605166437, 11.006119256480243, 11.22029279095821, -5.664082216594134, -6.012908296469624], time: 263.788
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 31.261447021541965, agent episode reward: [10.88828103551191, 10.514519191969098, 10.552767295948186, 10.797317701583673, -6.192653570367136, -5.29878463310377], time: 262.05
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 36.12870276543888, agent episode reward: [12.528799331666429, 12.124653937858596, 12.275352543289523, 12.513506121730282, -7.125199521485605, -6.188409647620347], time: 266.741
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 32.141661320997365, agent episode reward: [11.321341716804055, 10.956248264799111, 11.018130655175622, 11.25455206993756, -6.451057743971465, -5.95755364174752], time: 263.963
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 34.344547583415135, agent episode reward: [12.225125926312804, 11.882044377742721, 11.747361578392319, 12.0992015187475, -6.582857572621668, -7.026328245158544], time: 264.844
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 39.82781140569372, agent episode reward: [13.985728126667167, 13.589125802385057, 13.647112731922382, 13.903415548188095, -8.212981359908085, -7.084589443560896], time: 259.553
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 32.74511551651314, agent episode reward: [12.098958603898634, 11.738790803944292, 11.549788918536368, 12.011056838257765, -7.7550010951880415, -6.898478552935884], time: 262.203
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 31.559936153559036, agent episode reward: [12.060420679515923, 11.636999209508812, 11.469876176142991, 11.950174640523654, -8.768644087883713, -6.788890464248628], time: 261.269
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 24.29053655289945, agent episode reward: [9.45487458028471, 8.971433207457714, 8.822253808701364, 9.360170435779008, -7.231729573242364, -5.08646590608098], time: 264.813
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 25.192484013684616, agent episode reward: [9.316707613754087, 8.854602741532489, 8.790302449390124, 9.299462115905117, -6.1173634083034045, -4.951227498593792], time: 263.116
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 29.451105110216194, agent episode reward: [10.39667301147101, 9.945442112827187, 10.098815931488307, 10.350178328220437, -6.458340220170827, -4.881664053619919], time: 264.31
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 27.600140099070472, agent episode reward: [9.713276086529422, 9.310284011199768, 9.545318532675344, 9.641771385941922, -6.226264545909962, -4.384245371366027], time: 261.031
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 30.329361690973343, agent episode reward: [10.699573840276376, 10.37760891450481, 10.586818829675634, 10.626511675523922, -7.013870571143346, -4.947280997864054], time: 262.482
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 29.531232123623944, agent episode reward: [10.50802780032922, 10.206388054166519, 10.399787672089952, 10.466371225724718, -7.422161205526245, -4.627181423160219], time: 260.675
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 30.055328627447093, agent episode reward: [10.565135391236108, 10.283644887842827, 10.476400080179134, 10.499703973047275, -6.849125880576545, -4.920429824281707], time: 261.317
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 29.776057376268348, agent episode reward: [10.562039295344654, 10.337818727057602, 10.512603306577946, 10.482672031437282, -7.207729523951843, -4.911346460197289], time: 261.594
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 27.874266550491047, agent episode reward: [9.884157673471716, 9.635121628695892, 9.782203376004418, 9.801296129483523, -6.36220585838084, -4.866306398783661], time: 262.98
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 26.152580789846745, agent episode reward: [9.189496321080718, 9.004663480319309, 9.174643324685698, 9.138681846988316, -6.1290580178638105, -4.225846165363488], time: 262.052
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 23.84465130615562, agent episode reward: [8.333418331569346, 8.179261074455987, 8.352897092462252, 8.319293499875217, -4.95804162869864, -4.38217706350854], time: 262.06
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 23.610117383168994, agent episode reward: [8.358331679828384, 8.173131687845993, 8.349421736349184, 8.325498368469189, -4.806112277611937, -4.790153811711821], time: 261.879
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 26.36988976908884, agent episode reward: [9.293331980112377, 9.073683456867373, 9.24241122388605, 9.267710052575072, -5.445264197516533, -5.0619827468355], time: 235.559
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 25.34162215401516, agent episode reward: [8.958768374350504, 8.727154998885593, 8.919508938310214, 8.937818662765814, -5.369343379798149, -4.832285440498817], time: 206.863
...Finished total of 60001 episodes.
