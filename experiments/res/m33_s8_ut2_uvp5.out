0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -28.415970615591526, agent episode reward: [0.7749680521774523, 0.8373466006519051, 0.8138804913451757, 0.8178776039868548, -18.449169882873125, -13.210873480879789], time: 243.952
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -28.13276885215381, agent episode reward: [1.829218470135477, 2.2194579511682497, 2.184297918608633, 1.825460145452466, -12.876897185704449, -23.314306151814183], time: 317.261
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 9.63584050014908, agent episode reward: [3.7118833174099954, 3.699712504311946, 3.3338148733101973, 3.3147693423609033, -2.139010188981088, -2.2853293482628754], time: 323.792
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 12.351481432565846, agent episode reward: [4.465172186791257, 4.615483991676263, 3.679963082883917, 4.168780814291293, -2.0580662704212767, -2.519852372655608], time: 330.909
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 14.212583362230085, agent episode reward: [5.192677982002349, 4.990063337169493, 4.172092438432453, 4.784645928928503, -2.0510424628552784, -2.8758538614474345], time: 325.69
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 16.447303812334052, agent episode reward: [5.751461944104152, 5.785704889989663, 5.20079302880883, 5.547581145914222, -2.2757771497151107, -3.5624600467677023], time: 330.154
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 21.00230054369897, agent episode reward: [7.16402245049238, 6.946608500266273, 6.647923506536143, 6.801300425931889, -3.14672049233028, -3.4108338471974404], time: 328.133
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 25.42556621715964, agent episode reward: [8.706829802130764, 8.294320610238895, 7.998171815501922, 8.419402650195677, -3.354220424215869, -4.638938236691745], time: 331.959
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 37.47439987656399, agent episode reward: [12.524898855146818, 11.99022937047823, 12.133559736745948, 12.277707460795234, -4.548332036012669, -6.90366351058957], time: 328.204
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 38.765594652376514, agent episode reward: [13.039491269019072, 12.387814967266685, 12.659039482995208, 12.809262339834648, -4.5310656707095465, -7.5989477360295545], time: 330.538
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 42.11778606902762, agent episode reward: [14.129223647080625, 13.501926789238063, 13.852589973981663, 13.931755704476949, -5.409414300666317, -7.888295745083362], time: 330.139
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 43.94482839321443, agent episode reward: [14.948310296606662, 14.29113959418594, 14.614089186924373, 14.784904058653247, -6.5140543555067, -8.179560387649092], time: 329.355
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 39.64448758616942, agent episode reward: [13.673116611040044, 13.113744875984231, 13.321338221830741, 13.566472066783485, -7.182347705067557, -6.847836484401534], time: 329.801
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 36.58105512767307, agent episode reward: [12.444395777152113, 11.996190681255474, 12.244240199300238, 12.362911662837629, -6.382885582299706, -6.083797610572675], time: 327.336
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 34.17998916990126, agent episode reward: [11.667802589793123, 11.259844221545762, 11.568626148747095, 11.586245841326193, -6.309640729428705, -5.592888902082201], time: 331.804
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 38.40692102769843, agent episode reward: [13.098005692254915, 12.669293415044715, 13.000867810125671, 12.97330032102542, -6.724096718694012, -6.610449492058271], time: 328.093
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 36.30560573868949, agent episode reward: [12.524010755715771, 12.147592438064224, 12.373968959065461, 12.392305239499823, -6.463726052408356, -6.6685456012474384], time: 328.706
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 32.827234503107285, agent episode reward: [11.364932571399358, 11.016063668911494, 11.275557655389596, 11.271331806516322, -5.531331626629126, -6.569319572480359], time: 328.717
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 35.16096838870115, agent episode reward: [11.814827512294775, 11.523985411630838, 11.763144334298472, 11.701040976388875, -5.077482618408032, -6.564547227503785], time: 328.778
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 31.959531646730415, agent episode reward: [11.071111057970372, 10.783041965669335, 11.006226260332948, 10.89373558024094, -4.968827396298917, -6.825755821184258], time: 329.261
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 31.134604882648713, agent episode reward: [10.62750700776909, 10.43968487760887, 10.583440898032055, 10.477580508180097, -5.127525454881438, -5.866082954059962], time: 333.625
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 30.840652944383454, agent episode reward: [10.706546774112313, 10.578233331789303, 10.648875722197415, 10.571791226217817, -5.473072373070259, -6.191721736863129], time: 330.721
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 29.067067195897494, agent episode reward: [9.908777277405662, 9.794392889136008, 9.85834601916977, 9.77138616817912, -3.812815941913941, -6.453019216079125], time: 331.185
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 23.613830508660286, agent episode reward: [8.300012825229105, 8.224999155508632, 8.264499791329008, 8.213398166596205, -3.9874053849515985, -5.401674045051069], time: 327.734
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 25.814935220908374, agent episode reward: [8.73073197924711, 8.587560987576701, 8.677113169905196, 8.638040101972864, -4.456324628908022, -4.362186388885473], time: 328.338
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 23.188296056524134, agent episode reward: [8.671352044837779, 8.510539541889347, 8.63764163820641, 8.550054397032019, -5.692089937115137, -5.489201628326284], time: 328.796
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 22.90550369348374, agent episode reward: [8.378557123389099, 8.275459196351909, 8.2886905913334, 8.258116213649654, -4.520487502309408, -5.774831928930917], time: 326.155
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 22.68235022413406, agent episode reward: [8.05601741327126, 7.953031662563819, 8.04772728735576, 7.976411698579961, -4.004157634252335, -5.346680203384411], time: 324.257
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 22.366532110427777, agent episode reward: [8.213125904893525, 8.065739937583968, 8.198093009361592, 8.188684641905985, -4.04427849199672, -6.254832891320572], time: 319.395
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 22.510722558433788, agent episode reward: [8.480987571400986, 8.35709293340809, 8.387481098667177, 8.387226674400475, -4.2555076509240735, -6.846558068518867], time: 317.138
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 19.50376795127768, agent episode reward: [7.275410414986078, 7.2704307909223544, 7.288993168203466, 7.260169633098469, -4.236559963258909, -5.354676092673774], time: 318.873
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 22.529604654526672, agent episode reward: [8.264759493415982, 8.26227806916098, 8.320646020203048, 8.314093532666792, -4.396238714486879, -6.23593374643325], time: 318.121
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 18.838209940391327, agent episode reward: [7.284785950212601, 7.199378035931461, 7.299890955070037, 7.270354603493352, -4.261558559262588, -5.954641045053538], time: 318.342
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 21.03101972340368, agent episode reward: [8.320514733157005, 8.298931257392493, 8.370146226792109, 8.331208596287556, -5.080459193950985, -7.209321896274492], time: 317.099
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 21.596528901521886, agent episode reward: [7.916735099141115, 7.948477616538445, 8.053058907979425, 7.985989082508503, -4.415698164794943, -5.892033639850664], time: 318.311
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 23.035225542555086, agent episode reward: [8.306876660884017, 8.321961266092673, 8.368219531604707, 8.328848246039248, -4.593665968511946, -5.697014193553613], time: 320.503
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 23.84483784909777, agent episode reward: [8.613373434889452, 8.573098359372155, 8.62592948406679, 8.605949436515004, -4.644295438888981, -5.929217426856643], time: 316.262
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 21.293021066071365, agent episode reward: [7.844712248784561, 7.891441882372877, 7.91676527163132, 7.971222680831174, -3.96945372280953, -6.3616672947390365], time: 318.471
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 24.693588658085492, agent episode reward: [8.864221645916803, 8.752256346293615, 8.967765997785303, 8.953420717038483, -4.31458195271261, -6.529494096236101], time: 318.055
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 24.34441957724221, agent episode reward: [8.597845941020568, 8.526123078189631, 8.579440836730148, 8.551038870046877, -4.174220938354066, -5.7358082103909425], time: 317.811
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 20.88580424627586, agent episode reward: [8.099401875946446, 8.051946492385364, 8.166672916981206, 8.150211421540966, -4.315940037435328, -7.266488423142798], time: 316.206
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 20.344454669850652, agent episode reward: [7.745812482689222, 7.821682212730521, 7.927919012172541, 7.924581831304158, -3.970384727570917, -7.105156141474873], time: 315.517
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 20.785830808815373, agent episode reward: [7.301743751743242, 7.399085398383533, 7.490454557659743, 7.519285595953601, -4.498425618886979, -4.426312876037769], time: 317.448
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 21.819124363809998, agent episode reward: [7.471010564012751, 7.611971848477411, 7.698150600167362, 7.695662505091577, -4.385473254475877, -4.272197899463222], time: 316.618
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 22.143600410750288, agent episode reward: [7.81395928270192, 7.912092328965086, 7.990387182495723, 8.04844749302061, -5.312391458375494, -4.308894418057556], time: 318.872
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 20.080096627299216, agent episode reward: [7.526918870547886, 7.734436657128967, 7.756709205383249, 7.75173449822646, -6.124358207291614, -4.565344396695729], time: 317.323
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 18.77658029351448, agent episode reward: [7.052541248475064, 7.119093263362318, 7.132776509689455, 7.106686023147753, -5.460032670507874, -4.174484080652234], time: 316.709
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 26.527176321447648, agent episode reward: [9.207156639655087, 9.191458339109097, 9.180543087350578, 9.238356269064514, -5.908047358988338, -4.382290654743295], time: 315.691
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 27.103093806348298, agent episode reward: [9.492533135466642, 9.426362493336134, 9.416779525474547, 9.462942946077016, -5.756123526459341, -4.9394007675467], time: 315.748
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 24.6877257842758, agent episode reward: [8.527079745663782, 8.606395998358932, 8.540713929388684, 8.629580740529008, -4.478052658610231, -5.137991971054376], time: 316.037
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 24.431232138612646, agent episode reward: [8.428630702913043, 8.553807003486385, 8.538673948906224, 8.52962698860004, -5.315692627819749, -4.303813877473294], time: 314.733
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 26.08457031148931, agent episode reward: [9.216693141004841, 9.184463877725713, 9.275726458814269, 9.233403934975275, -5.384548806029908, -5.44116829500088], time: 315.339
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 26.96610617429622, agent episode reward: [9.266952367922208, 9.317012192858321, 9.240129945241536, 9.284478392209865, -5.064981382038543, -5.077485341897169], time: 313.887
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 28.372553666077494, agent episode reward: [9.710442800804397, 9.74023053350506, 9.664203454843712, 9.762956830230976, -5.741986195329868, -4.763293757976785], time: 312.864
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 29.687094262411748, agent episode reward: [10.171896372013375, 10.194348199522409, 10.143022890456724, 10.204931593417918, -6.348555935780031, -4.6785488572186384], time: 313.759
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 26.900833373435272, agent episode reward: [9.408270622764736, 9.456423122091714, 9.292399059386916, 9.438942666465605, -6.139931018777216, -4.555271078496488], time: 316.991
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 25.149550807061374, agent episode reward: [9.07331270675413, 9.059262700044854, 8.93330040045054, 9.046979093327831, -6.4664060659431595, -4.496898027572819], time: 313.755
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 27.78102336994806, agent episode reward: [9.7771487811255, 9.79000888719381, 9.66604972384739, 9.827856604965428, -6.602362106689839, -4.677678520494229], time: 311.37
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 29.430407820226407, agent episode reward: [9.931751662481048, 10.044218317043144, 9.98536749838318, 10.184026505461242, -6.526396749339879, -4.188559413802332], time: 312.738
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 27.46018242996999, agent episode reward: [9.38072818093453, 9.387468095833418, 9.342714149514482, 9.373991716163465, -5.801116137512983, -4.223603574962919], time: 293.414
...Finished total of 60001 episodes.
