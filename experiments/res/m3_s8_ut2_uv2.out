0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -37.49784901769153, agent episode reward: [0.8433081557575278, 0.8598792222744928, 0.9013081220882093, 0.891764258688365, -29.978596382545927, -11.015512393954198], time: 198.406
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -28.576215043435795, agent episode reward: [2.570891241709344, 2.697936173601618, 2.807744364563199, 2.8121488243231814, -26.174188025180406, -13.290747622452729], time: 256.922
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 11.550448400098249, agent episode reward: [4.494021781062254, 4.421359357416015, 4.4484233759934195, 3.9889158203254236, -2.576826982088366, -3.225444952610499], time: 259.133
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 14.662706539715058, agent episode reward: [5.172123582243081, 5.057952140572339, 4.828835079603868, 4.712120252585357, -2.8322160534205887, -2.276108461869001], time: 262.493
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 19.01276308710435, agent episode reward: [6.677337315673038, 6.613902779889424, 6.22169590677156, 6.100331950404041, -2.884379273426795, -3.716125592206914], time: 254.95
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 18.670962445607547, agent episode reward: [6.540282395904396, 6.327802736515399, 5.841684423538965, 5.964848838608563, -2.8763293760186315, -3.127326572941142], time: 257.211
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 24.997388295171252, agent episode reward: [8.471656085347577, 8.454005714660823, 7.8478486540400665, 7.776743112103619, -3.6683427005440628, -3.8845225704367685], time: 256.448
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 29.965764876797692, agent episode reward: [10.248978297968355, 10.112874995990026, 9.42734030364015, 9.632977519731085, -4.786025099841063, -4.670381140690859], time: 255.897
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 27.623450968204057, agent episode reward: [9.321184455845138, 9.254513886426722, 8.780622926281634, 9.009164084450143, -4.983496779222003, -3.758537605577578], time: 260.181
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 35.09753353525499, agent episode reward: [11.842041297865551, 11.819258247379352, 11.202409191981987, 11.565441584006035, -5.602286293997737, -5.729330491980196], time: 251.737
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 35.64017503974891, agent episode reward: [11.936242844044125, 11.886142997436572, 11.498186176484374, 11.720213689818943, -6.091935399945305, -5.308675268089803], time: 253.629
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 30.9945478082098, agent episode reward: [10.667820077496176, 10.602599715502281, 10.051238998890186, 10.44505192037841, -5.41371224951381, -5.358450654543442], time: 260.004
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 35.277024338895835, agent episode reward: [12.026989699479847, 11.880842707088433, 11.435483197890152, 11.777276401415726, -5.337310120192235, -6.506257546786092], time: 259.974
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 37.93049621445307, agent episode reward: [13.059933363090542, 12.933898674101629, 12.501676837380895, 12.861026398705784, -7.247722955827002, -6.178316102998777], time: 262.7
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 42.798242398721804, agent episode reward: [14.570299165277564, 14.538301760890468, 14.151014187193566, 14.44140441551014, -8.499851646853335, -6.402925483296603], time: 261.975
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 41.76133294910363, agent episode reward: [14.348728194347235, 14.320407093036785, 14.016867891507646, 14.174540912563838, -8.807860230765604, -6.291350911586267], time: 258.994
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 36.236888721421536, agent episode reward: [13.243486857679605, 13.20756522884632, 12.974013736350047, 13.106834119456943, -8.654054332320086, -7.640956888591301], time: 258.976
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 35.903314259897414, agent episode reward: [12.883518346081127, 12.928169290982245, 12.760232895600042, 12.781945585212162, -8.073394370643795, -7.3771574873343635], time: 258.207
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 33.37190027150719, agent episode reward: [12.118005173103422, 12.105901406916182, 11.994854527057027, 11.996514213170133, -7.654143071960964, -7.189231976778619], time: 258.72
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 30.84588247849505, agent episode reward: [11.129108782129519, 11.099949349072048, 11.040492293757609, 11.06398025124812, -6.807332397155818, -6.680315800556431], time: 260.288
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 18.105487894169375, agent episode reward: [7.196692540169724, 7.174841030735874, 7.181955498809386, 7.111192811367806, -5.051191472036133, -5.50800251487728], time: 256.537
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 16.096712339247226, agent episode reward: [6.553393951215383, 6.54175714415296, 6.472706420168195, 6.449028189885966, -4.8942752058626935, -5.025898160312585], time: 258.732
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 20.322524902545293, agent episode reward: [8.157244326124498, 8.124499871299685, 8.098807506098128, 7.995747948404588, -7.941465428244697, -4.112309321136911], time: 259.027
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 15.582365969375857, agent episode reward: [7.224288247201636, 7.1104278280170945, 7.126322184577942, 7.047869426077565, -8.783421305327353, -4.1431204111710285], time: 257.254
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 17.548566786659613, agent episode reward: [7.183828813005114, 7.081893992541587, 7.03507249185544, 7.039491948203957, -7.1326953575386485, -3.6590251014078374], time: 260.02
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 15.95402301264121, agent episode reward: [6.778026826582453, 6.691897566806501, 6.678852862730795, 6.658633647141703, -6.278032761348675, -4.575355129271566], time: 257.954
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 18.88538968967837, agent episode reward: [7.802201005997124, 7.779944611480735, 7.819342460136266, 7.747176950194194, -7.8836996825505645, -4.379575655579386], time: 260.095
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 18.21104843843934, agent episode reward: [7.55344576251153, 7.386574628930896, 7.489498529160169, 7.510463045898139, -7.551096222841849, -4.177837305219546], time: 258.071
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 20.780443487436443, agent episode reward: [8.215583545684677, 8.127985864418587, 8.181474885252511, 8.261972052141216, -8.079184363242849, -3.9273884968177035], time: 262.164
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 21.021794651953286, agent episode reward: [8.180452352459659, 8.161113581663194, 8.191925636227554, 8.213231024599532, -7.7933101235430735, -3.93161781945358], time: 258.205
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 21.50876105622938, agent episode reward: [7.869020374757359, 7.8620059996463505, 7.838451670281736, 7.868880696768374, -5.985833013880686, -3.943764671343757], time: 256.752
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 25.526324052650665, agent episode reward: [8.663816893211985, 8.678686418621956, 8.725691438199064, 8.75880882573234, -5.7184953491401735, -3.582184173974507], time: 259.696
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 26.130456729659265, agent episode reward: [8.959603413688544, 9.015590849458123, 8.983865782410254, 9.08703608817751, -6.113793723472401, -3.801845680602762], time: 262.771
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 27.361422468100436, agent episode reward: [9.285867074947905, 9.266228816924515, 9.231364469024538, 9.296957192043038, -7.026910051220224, -2.692085033619337], time: 257.262
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 25.16856266444423, agent episode reward: [8.68203071009523, 8.662356602653363, 8.690721961771432, 8.714238699986943, -6.1788015740779985, -3.4019837359847416], time: 256.74
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 25.8560651525577, agent episode reward: [9.284669320433672, 9.218169441032373, 9.203890483422624, 9.284323151609053, -6.814347099506947, -4.320640144433069], time: 257.943
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 25.94089896790874, agent episode reward: [9.750978797797375, 9.653428182190805, 9.678371184749357, 9.749461341631948, -7.160181977705903, -5.731158560754843], time: 260.486
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 26.427245944481996, agent episode reward: [9.292445994429475, 9.254236100898005, 9.33189314115228, 9.310261865504275, -7.230436480332643, -3.531154677169399], time: 256.496
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 24.191766924509093, agent episode reward: [8.523603371750333, 8.510726443740031, 8.46773270287353, 8.435896565381704, -7.190970458574794, -2.5552217006617135], time: 258.619
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 29.03089664606709, agent episode reward: [9.949582455749765, 9.994884588155351, 9.843245073899787, 9.84781009017456, -7.252993108520282, -3.351632453392088], time: 253.059
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 23.96703814206137, agent episode reward: [8.522809345835013, 8.46218625202231, 8.499859236577146, 8.41377080938724, -7.415198177493782, -2.5163893242665525], time: 257.211
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 14.74821923454375, agent episode reward: [6.695544589914778, 6.655269335441753, 6.638821300872374, 6.545456256487329, -9.265002550663482, -2.5218696975090045], time: 263.237
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 15.534985687001614, agent episode reward: [6.8216262522651, 6.686695303712043, 6.74313028114906, 6.700918340993178, -7.819517817916245, -3.597866673201525], time: 261.041
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 15.468394864561894, agent episode reward: [6.4926785432054315, 6.501307552031648, 6.515619699390438, 6.4317689889046665, -7.171253665488371, -3.301726253481919], time: 259.645
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 18.774618820408826, agent episode reward: [6.599151332292443, 6.657882429208175, 6.6438744425073475, 6.527344956587134, -4.945300800575493, -2.7083335396107833], time: 255.015
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 20.24087763139267, agent episode reward: [6.905806394604189, 7.046715368995276, 6.981307714237835, 6.895760033919625, -4.877136994590338, -2.7115748857739157], time: 256.046
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 18.680624969183906, agent episode reward: [6.484126401340705, 6.483045494411095, 6.554111518844611, 6.448741288364982, -4.328701558381278, -2.96069817539621], time: 258.254
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 14.232528369586994, agent episode reward: [5.600865653736746, 5.608095168947704, 5.552878263221919, 5.599909181600082, -4.1895054750137986, -3.9397144229056584], time: 262.692
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 13.101112137893121, agent episode reward: [4.944169321110227, 4.904676639736759, 4.9595187235028115, 4.936820536022094, -3.7939261399332955, -2.8501469425454755], time: 254.758
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 15.43552904009782, agent episode reward: [5.849262656017499, 5.958411536737114, 5.870509536794318, 5.876319187632445, -5.093872696556628, -3.02510118052693], time: 258.345
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 15.805954966206977, agent episode reward: [5.924290035604745, 6.008050516956314, 6.018872113343645, 5.987001808758751, -4.739777145868859, -3.3924823625876175], time: 255.674
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 17.99770029103663, agent episode reward: [6.400454191438856, 6.3994749675229015, 6.41057168156996, 6.4500204160616095, -4.211018566615582, -3.451802398941114], time: 259.754
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 19.269597222394594, agent episode reward: [6.595463432125991, 6.641533603255704, 6.651390830976753, 6.537234888720714, -4.172887526646502, -2.9831380060380694], time: 259.684
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 22.030610957968968, agent episode reward: [7.457466692987103, 7.592147733218746, 7.523083440178703, 7.501199897088681, -4.951581459450152, -3.091705346054114], time: 255.077
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 21.252939568999057, agent episode reward: [7.394114173215481, 7.404261203654985, 7.320219397412806, 7.220589574519587, -5.0271219009221895, -3.059122878881618], time: 256.048
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 20.92884664747712, agent episode reward: [7.294786053490201, 7.239922815686723, 7.092252351888841, 6.993443751384426, -4.975370077564721, -2.7161882474083487], time: 263.714
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 24.39539732204303, agent episode reward: [8.255385971725824, 8.203089741788228, 8.121038749399222, 8.016509361474501, -5.827557642598245, -2.373068859746495], time: 259.561
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 28.272687717061913, agent episode reward: [9.623904227920354, 9.615781092972309, 9.38674240592575, 9.38430937250645, -6.9821336482822645, -2.7559157339806863], time: 260.599
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 29.741872895650324, agent episode reward: [10.014735463696864, 10.040462055381974, 9.87099697903336, 9.78282400043766, -7.470336831177715, -2.4968087717218146], time: 257.88
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 31.484898712014626, agent episode reward: [10.625139697998856, 10.632268135830826, 10.477063375983663, 10.305834393659175, -7.708537396926672, -2.84686949453122], time: 223.37
...Finished total of 60001 episodes.
