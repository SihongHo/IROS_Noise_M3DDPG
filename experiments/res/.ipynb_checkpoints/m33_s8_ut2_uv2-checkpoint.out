0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Uncertainty type is:  Action ; Uncertainty level is:  2.0
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -28.11546967494899, agent episode reward: [0.8568379964751854, 0.8067574924033701, 0.7964490011781477, 0.8354010368671855, -17.90119494894009, -13.509720252932787], time: 250.087
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -15.165488634990572, agent episode reward: [2.6834244394873004, 3.272543754281015, 3.3033861874235444, 3.277463107282405, -10.340974432076548, -17.361331691388287], time: 320.496
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 10.24127148179201, agent episode reward: [3.3670817471075134, 3.7695597534418757, 3.833559391207283, 3.9825898974800316, -2.079625999466573, -2.6318933079781215], time: 323.857
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 14.814878037760185, agent episode reward: [4.596796895297584, 4.76975657684482, 4.953542420323731, 5.327423065628829, -2.405417544165976, -2.4272233761688056], time: 326.828
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 14.455075049189785, agent episode reward: [4.534833090615603, 4.4344130833928554, 4.965189065385401, 5.254036302780496, -2.2814141884429544, -2.451982304541616], time: 328.735
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 15.455413639151253, agent episode reward: [4.943732630064316, 4.997095624058919, 5.1549324187167525, 5.434356543875942, -2.675416882135925, -2.3992866954287484], time: 331.387
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 19.686858270932856, agent episode reward: [6.3978407176795775, 6.63300974747209, 6.311548052101507, 6.583335298730557, -3.078835117956632, -3.1600404270942466], time: 330.443
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 22.739507146794534, agent episode reward: [7.39465666936617, 7.609857472205752, 7.021890517663905, 7.630936132421533, -4.04053060288932, -2.877303041973503], time: 330.247
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 25.24436169991917, agent episode reward: [8.110378456260804, 8.607223211665275, 8.152347115948965, 8.328455880143721, -4.4179825588679, -3.536060405231694], time: 330.658
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 23.277947339199464, agent episode reward: [7.479158715535803, 7.749041589810817, 7.426149642260791, 7.66948456518671, -3.860327396022076, -3.1855597775725824], time: 331.275
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 26.84777945693525, agent episode reward: [8.772359751216495, 8.993747063943482, 8.408012349341199, 8.940531540523695, -4.6788321141497144, -3.588039133939913], time: 331.836
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 29.812077826049865, agent episode reward: [9.760099848696344, 9.869187285222525, 9.458186200039648, 9.996491540164108, -4.810567271383212, -4.461319776689546], time: 330.634
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 33.144025867168686, agent episode reward: [10.862691228965044, 10.7925585898729, 10.565297392251267, 10.898726534471887, -4.227718430250233, -5.747529448142177], time: 327.883
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 33.60706020453668, agent episode reward: [11.217578404455075, 10.900011732253839, 10.818911834958502, 11.20250219895504, -4.9640950722630555, -5.567848893822716], time: 330.356
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 34.984610754326845, agent episode reward: [11.501702178532764, 11.197125429868105, 11.292552893978494, 11.480861318227026, -5.286466963378833, -5.201164102900715], time: 331.893
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 37.57984713881604, agent episode reward: [12.45457012159047, 12.191447059405975, 12.299490672458523, 12.471408900909816, -5.5507896775944525, -6.2862799379542915], time: 331.232
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 41.69190684124076, agent episode reward: [13.84097662867856, 13.665357690499517, 13.809290026615216, 13.917267321906397, -7.170413477427712, -6.370571349031221], time: 330.124
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 45.202131396598645, agent episode reward: [14.916003093930511, 14.79903330424807, 14.9331673161269, 15.083725207658775, -7.630098960469212, -6.899698564896394], time: 330.104
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 47.57699286809194, agent episode reward: [15.652558663876126, 15.509671943771329, 15.563004882796609, 15.689754170768895, -7.9941797367817795, -6.843817056339237], time: 333.517
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 43.913780353056204, agent episode reward: [14.793333409163953, 14.748881407281242, 14.71981463609097, 14.86183402246716, -7.316002696499714, -7.8940804254474095], time: 330.592
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 34.697851206823984, agent episode reward: [11.859176575512532, 11.701551761220049, 11.734412661511863, 11.926285720902108, -6.3602369518722845, -6.163338560450282], time: 331.249
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 37.32300119542062, agent episode reward: [12.984991454849391, 12.69042548995512, 12.898844989111268, 12.903202136802458, -5.9808826755072495, -8.173580199790365], time: 329.622
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 38.36125153477148, agent episode reward: [13.112177971498856, 12.783352971639685, 13.04442803023553, 13.013995667424126, -6.543975591111528, -7.048727514915184], time: 333.018
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 39.907124068803604, agent episode reward: [13.455988481102711, 13.194334181982462, 13.40782959746585, 13.376878590837363, -5.696018851979268, -7.83188793060551], time: 331.115
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 36.25391490957616, agent episode reward: [12.420808118128255, 12.321367542422456, 12.460691611578222, 12.463632596303581, -5.95059573321151, -7.461989225644845], time: 328.229
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 32.69152081000563, agent episode reward: [11.045982022735876, 10.885221522694538, 11.0144818999169, 10.986185978080272, -3.9521253742238898, -7.288225239198061], time: 328.491
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 25.96255137350323, agent episode reward: [9.25911262290099, 8.94369380219025, 9.174523476197857, 9.041471936036546, -3.568225346107895, -6.888025117714514], time: 327.188
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 30.28420649970569, agent episode reward: [10.483114070160989, 10.18058716470126, 10.431628149911871, 10.331625293723063, -4.640877407093789, -6.501870771697702], time: 324.349
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 27.13832092302677, agent episode reward: [9.324461402190536, 9.057403427414297, 9.269229784853719, 9.105452259327613, -3.2376889073859827, -6.380537043373407], time: 320.994
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 27.750108000997532, agent episode reward: [9.70419030054806, 9.433681934431709, 9.625076700067984, 9.502614133695358, -4.153508712654973, -6.361946355090607], time: 319.877
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 22.904360116296978, agent episode reward: [8.075767660217409, 7.863745823923749, 8.08333810946684, 7.932880366545592, -3.1713366595824217, -5.8800351842741865], time: 318.681
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 19.14753456003143, agent episode reward: [7.474254711020549, 7.307482752218592, 7.535756856502742, 7.423102203187945, -4.846842833769306, -5.746219129129085], time: 318.811
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 18.644690892536946, agent episode reward: [7.036121108415694, 6.811521899505244, 7.065325371462473, 6.951672280728485, -3.53015159963234, -5.689798167942606], time: 319.96
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 18.28207387232947, agent episode reward: [7.16094400149716, 6.969592660586268, 7.241105048384905, 7.062610015650165, -4.04204550001865, -6.110132353770376], time: 321.067
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 19.893326560490365, agent episode reward: [7.569421109377098, 7.382070298897511, 7.635170253523817, 7.490469091089715, -3.931735341173003, -6.25206885122477], time: 320.157
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 21.367819425341274, agent episode reward: [8.15909586960131, 7.974551128509635, 8.282440532907426, 8.012461687072395, -3.736958053536705, -7.32377173921279], time: 318.589
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 23.463588681794857, agent episode reward: [9.644640993588023, 9.430613555270288, 9.736764613471353, 9.456274189854277, -5.736289368638477, -9.068415301750607], time: 320.916
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 24.248552679459024, agent episode reward: [8.950349636733923, 8.704028195299669, 8.983113861339854, 8.807886807721971, -3.7939767448547563, -7.402849076781639], time: 320.311
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 20.291040151717024, agent episode reward: [8.2139117422194, 8.068562870466641, 8.27278732821588, 8.027480647243705, -4.348031390610285, -7.943671045818314], time: 318.552
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 21.99102878134131, agent episode reward: [8.445539518119235, 8.360192266821366, 8.466652025711284, 8.293232469726767, -4.16813493244087, -7.4064525665964736], time: 318.341
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 20.85338920877701, agent episode reward: [7.900354423458252, 7.766179760709195, 7.909030589584947, 7.759058490863243, -3.0362780363101187, -7.444956019528507], time: 315.619
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 16.968065966683547, agent episode reward: [7.160561496439941, 7.213769661433113, 7.433107023807597, 7.250456457870954, -5.076245965145099, -7.0135827077229616], time: 316.322
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 16.2888419765541, agent episode reward: [6.540356217671443, 6.6250986619792505, 6.675586014788279, 6.561144843222571, -4.298291869910688, -5.815051891196758], time: 317.909
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 17.4110160894434, agent episode reward: [6.956292803080933, 7.015909547756593, 7.062013993861545, 7.021836788204643, -3.9173581376503526, -6.727678905809959], time: 317.014
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 13.477303191807419, agent episode reward: [6.07990297552511, 6.102311019674018, 6.115838497145971, 6.097706010968401, -4.477465147502171, -6.440990164003909], time: 316.617
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 11.222005638288424, agent episode reward: [5.6939529541633105, 5.662373306754549, 5.619481213110948, 5.671908905660628, -4.087326907769955, -7.338383833631057], time: 320.465
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 9.8698617077877, agent episode reward: [4.8558023132783745, 4.852693067386259, 4.817278172499941, 4.769166263569216, -3.3850363920677347, -6.040041716878354], time: 317.194
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 12.73011520635041, agent episode reward: [5.475027018926034, 5.380515959980071, 5.405051696742302, 5.374495274676086, -2.5741284263852613, -6.330846317588822], time: 317.08
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 14.119951996768261, agent episode reward: [5.88039605645138, 6.002026427240143, 5.983002856419471, 5.9669378542378455, -3.0032532106799708, -6.709157986900605], time: 317.966
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 19.78278936306084, agent episode reward: [7.35576863294604, 7.5150630804208305, 7.66082491652101, 7.527203574916782, -2.8799728363218122, -7.3960980054220125], time: 316.513
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 17.996349355883844, agent episode reward: [6.86249386485471, 7.203394282620951, 7.143921105519538, 7.033291290107502, -3.1181367552209096, -7.128614431997943], time: 316.32
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 16.337875192965225, agent episode reward: [5.952263835614323, 5.997536019247555, 5.9136224072119825, 5.804060003404496, -2.1455206119236374, -5.184086460589492], time: 316.634
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 16.621843537173568, agent episode reward: [6.189174064022306, 6.42970646030317, 6.288554179066832, 6.202439383676885, -1.9714964416195502, -6.516534108276075], time: 313.483
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 20.773863843812382, agent episode reward: [7.107744461688372, 7.324801181283339, 7.2702600478707184, 7.0886099649793595, -2.1052302389608677, -5.912321573048539], time: 315.434
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 21.82570756326359, agent episode reward: [7.345330949845461, 7.514758236107608, 7.393509298026068, 7.3227690848701625, -2.0481125930315347, -5.70254741255417], time: 313.154
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 22.73854275519843, agent episode reward: [7.584645492228341, 7.874515037717108, 7.792824859044965, 7.597027541611204, -1.434302002118474, -6.676168173284714], time: 311.883
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 21.3558578830954, agent episode reward: [7.295877115004465, 7.312565336423002, 7.355614702452467, 7.153373596138146, -1.876857703478846, -5.884715163443837], time: 317.193
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 22.135829743056362, agent episode reward: [7.493689570477737, 7.519955874928506, 7.466523278797169, 7.369586147283488, -1.655914810806594, -6.058010317623943], time: 315.442
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 20.991478823656088, agent episode reward: [7.215969185315691, 7.287439674232517, 7.2422283976876045, 7.143984518518504, -2.0054875251988857, -5.892655426899342], time: 314.161
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 19.833213031997968, agent episode reward: [6.8356199373778015, 6.919082831420134, 6.777375113341164, 6.6888338121039155, -1.7824340301181738, -5.605264632126877], time: 264.269
...Finished total of 60001 episodes.
