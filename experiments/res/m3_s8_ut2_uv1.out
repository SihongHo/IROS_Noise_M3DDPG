0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Uncertainty type is:  Action ; Uncertainty level is:  1.0
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -41.92914831517267, agent episode reward: [0.38679759094759947, 0.5014531537813545, 0.5117026936602825, 0.47914361968128766, -22.007418813563604, -21.800826559679592], time: 196.395
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -11.42587106019925, agent episode reward: [2.7625114370967223, 3.136364170146101, 3.1286106686108175, 3.2790493449262437, -13.00242433555613, -10.729982345423007], time: 257.614
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 7.604769831189565, agent episode reward: [2.8371297816743635, 3.0470972331256463, 3.342840840564675, 3.2171559084399197, -1.9378578348441928, -2.9015960977708457], time: 250.922
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 12.939328805304823, agent episode reward: [4.105656138594678, 4.30268961307361, 4.83609111295422, 4.594841336345728, -2.1097190978613605, -2.7902302978020503], time: 261.521
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 18.373505128755635, agent episode reward: [5.940458592890897, 5.8375361882969825, 6.408999124046721, 6.420006686074044, -3.0362734875311377, -3.1972219750218676], time: 260.203
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 21.15289117041693, agent episode reward: [6.757626050687976, 6.605844680111877, 7.353464716430077, 7.078325553298353, -3.2096438014778705, -3.432726028633483], time: 257.928
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 28.89259288194179, agent episode reward: [9.124606252752523, 9.21015229570318, 9.793660679042908, 9.506007066300858, -4.476690086907763, -4.265143324949915], time: 254.304
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 32.89952818357447, agent episode reward: [10.668354848317282, 10.601737086275055, 10.947617808213927, 10.894157513678747, -5.157968149666665, -5.054370923243872], time: 252.176
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 38.00353761976832, agent episode reward: [12.283199321679545, 12.262064028516813, 12.73725294127281, 12.60856197152948, -6.334644305911395, -5.552896337318936], time: 256.525
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 38.390541496355226, agent episode reward: [12.400795777033453, 12.511599834747376, 12.626053880012977, 12.668061241212813, -5.74794757570903, -6.068021660942364], time: 259.253
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 41.74253623820761, agent episode reward: [13.704210930923415, 13.689067164166095, 13.681742391437368, 13.57950098521636, -6.2798894804441, -6.632095753091525], time: 259.773
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 47.37148104105653, agent episode reward: [15.585659236179461, 15.531224872254082, 15.635886351471996, 15.49285437781009, -6.560303036428139, -8.313840760230955], time: 261.527
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 41.17058270161966, agent episode reward: [13.484303884412947, 13.271703780628064, 13.504212669113262, 13.449964621956406, -6.001709518037251, -6.53789273645377], time: 256.562
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 45.598193123402076, agent episode reward: [15.089862961753992, 15.048706255964426, 15.082092859833965, 15.069898838047235, -5.897410978256077, -8.794956813941466], time: 259.71
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 53.54262890637615, agent episode reward: [17.60694916547273, 17.619081315518358, 17.544497904886597, 17.60396696566029, -6.843184452041596, -9.988681993120249], time: 254.401
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 56.75498467207236, agent episode reward: [18.61185188628242, 18.610396739344186, 18.533326118307308, 18.63772334024913, -6.2932181317063165, -11.34509528040437], time: 261.82
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 45.70777145585665, agent episode reward: [15.367475829627395, 15.200839182751203, 15.096404593273087, 15.307054970943742, -7.623570227671645, -7.640432893067138], time: 255.345
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 37.82697480268971, agent episode reward: [12.68400881447715, 12.465846350258754, 12.395144046294597, 12.60815323878035, -6.510956355157936, -5.815221291963198], time: 260.709
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 40.266948097995524, agent episode reward: [13.562672307070567, 13.459168930454656, 13.28937048550874, 13.500085928085078, -5.699071997535466, -7.845277555588051], time: 260.959
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 39.409703334707054, agent episode reward: [13.304960228169305, 13.15853406750934, 13.035603857966048, 13.182970198741224, -5.945567376258641, -7.32679764142022], time: 251.421
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 40.65722590738537, agent episode reward: [13.634044797536692, 13.525688982367182, 13.354109738969017, 13.574248643444912, -6.063717889795468, -7.367148365136971], time: 252.299
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 35.870771181167875, agent episode reward: [12.35378459873689, 12.331230011894382, 12.146233384441471, 12.275882647081009, -6.5022551096433, -6.73410435134258], time: 261.79
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 31.99728214551186, agent episode reward: [10.833165017990257, 10.769459280811446, 10.733953310584996, 10.79362889869975, -5.2972837755032245, -5.835640587071363], time: 260.097
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 33.20907856670553, agent episode reward: [11.422775014393403, 11.353511651097287, 11.355090911095498, 11.375233595605376, -6.6988162473999875, -5.598716358086036], time: 261.392
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 21.326761293474906, agent episode reward: [7.908809674312239, 7.832315166324228, 7.7553508887090885, 7.802318926456498, -5.570595911625848, -4.4014374507013025], time: 255.164
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 24.19221287966782, agent episode reward: [8.934747915027717, 8.81473004519973, 8.829845750054762, 8.798747687082102, -6.2363100301302605, -4.94954848756623], time: 252.135
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 17.033741456595024, agent episode reward: [7.152139974365129, 7.074203156412896, 7.079159128666957, 7.059582261794094, -5.672447176827305, -5.658895887816745], time: 257.813
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 13.33204033536039, agent episode reward: [6.5232292866286095, 6.41758925799384, 6.555200388515534, 6.498625874456351, -6.2662590103082705, -6.396345461925674], time: 254.848
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 14.256517942676052, agent episode reward: [6.373269337961359, 6.267723807621614, 6.287651859727764, 6.370122413149047, -4.605757386429232, -6.436492089354502], time: 262.244
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 16.680185445395544, agent episode reward: [6.913941914150475, 6.883840091603609, 6.954809032212787, 6.9456285098397545, -6.464844915097623, -4.553189187313456], time: 248.841
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 12.487427488171697, agent episode reward: [6.339375791532932, 6.360910361849708, 6.291115532989001, 6.379145745077092, -7.234748015445366, -5.648371927831669], time: 251.878
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 8.339524444871993, agent episode reward: [5.937180400690254, 5.89196440359229, 5.89397370805311, 5.969028645262743, -8.341945493768174, -7.01067721895823], time: 253.868
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 10.994298439999048, agent episode reward: [5.799865519180785, 5.762391540381539, 5.78524570275562, 5.844888378427845, -6.349214541503965, -5.848878159242776], time: 253.767
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 12.436759067601185, agent episode reward: [5.849732585926982, 5.909585059663726, 5.92034699109605, 5.998119453881334, -5.388797988393799, -5.85222703457311], time: 262.779
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 9.953508881856877, agent episode reward: [5.61934664591163, 5.685547905573745, 5.631870131907646, 5.711288946743254, -5.590226401431224, -7.1043183468481725], time: 259.559
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 13.241009764829258, agent episode reward: [6.221908756873545, 6.248060226985399, 6.264052294122923, 6.31775194246934, -4.662254685705474, -7.148508769916475], time: 261.242
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 15.504597894574196, agent episode reward: [6.36857508009895, 6.382222009447195, 6.415370067032491, 6.438677994094816, -4.899131907098815, -5.201115349000438], time: 261.876
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 15.162135088084524, agent episode reward: [6.195464197881093, 6.174409497389117, 6.275071636110799, 6.288842936819623, -4.987176707385468, -4.784476472730639], time: 260.015
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 15.383524214981941, agent episode reward: [6.049686490860735, 6.1310706725517905, 6.098177152446231, 6.141316367948135, -5.400029071903364, -3.636697396921586], time: 258.08
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 16.481656260196395, agent episode reward: [6.249860354429038, 6.405809916166729, 6.358829769884508, 6.4158274332851395, -5.218059328498518, -3.7306118850705006], time: 252.19
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 18.373439791211737, agent episode reward: [6.9567424039181445, 7.0365374726247225, 6.9335691135863575, 7.064452372487647, -5.127899038637683, -4.489962532767451], time: 254.479
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 14.748630077155717, agent episode reward: [6.380230544925904, 6.382968972835046, 6.454514301124731, 6.499034320374029, -7.022300101631244, -3.945817960472748], time: 261.258
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 17.910994209267148, agent episode reward: [7.301291174610277, 7.369150282243365, 7.414117304391062, 7.4335246547888145, -6.786690772888749, -4.820398433877622], time: 260.322
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 14.426660361898696, agent episode reward: [6.068192870155122, 6.152423861617659, 6.029828037829616, 6.132795945942149, -5.393714694743834, -4.562865658902016], time: 259.011
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 16.732214789056382, agent episode reward: [6.920406166884497, 6.900965737039205, 6.728551283016432, 7.019884039355451, -5.813297365886118, -5.024295071353085], time: 265.143
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 18.272602320929362, agent episode reward: [7.041763888864577, 7.019806989711908, 6.927721793854707, 7.2220406482577255, -4.996923897533101, -4.941807102226456], time: 259.265
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 13.956026553637901, agent episode reward: [5.882517867275102, 5.980734169187747, 5.771890333053274, 6.0974963674046965, -5.759041558730372, -4.017570624552544], time: 260.007
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 15.381527832242806, agent episode reward: [5.867910647755509, 6.030406003514408, 6.026216052335985, 6.246022641451531, -5.22063328156663, -3.568394231247994], time: 252.015
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 17.614107460089542, agent episode reward: [6.31204697355682, 6.490006018738473, 6.4454997935871745, 6.668001045646375, -4.859902315402933, -3.4415440560363675], time: 255.292
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 16.226322090874753, agent episode reward: [6.008432681658442, 6.089620900303609, 5.95939447076675, 6.264887286585746, -4.418305002425333, -3.6777082460144612], time: 257.453
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 16.460561793530005, agent episode reward: [5.902279667211821, 5.897687825349803, 5.828773823118913, 6.166731750275116, -3.8772178021437407, -3.457693470281908], time: 259.956
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 15.341443657846824, agent episode reward: [5.869378004900135, 5.784973127780501, 5.520689421935501, 6.082312950103942, -5.398956583992543, -2.5169532628807074], time: 263.616
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 17.41854960951839, agent episode reward: [6.373511223083367, 6.243817202456528, 6.097948474611541, 6.40606455587987, -5.03750771581991, -2.6652841306930024], time: 259.607
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 19.32635413004957, agent episode reward: [7.036684175892867, 6.925774420276675, 6.569033753688988, 7.115408331632801, -4.919655877202936, -3.4008906742388243], time: 254.743
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 21.08320824170307, agent episode reward: [7.6169408289237515, 7.402072940655052, 7.220555544821595, 7.624181019812131, -5.2890598267638245, -3.491482265745641], time: 263.666
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 22.577585823314195, agent episode reward: [8.028695065282415, 7.744715796782486, 7.706528209016175, 8.187789569036102, -5.506400347114036, -3.5837424696889437], time: 262.638
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 23.248597240443328, agent episode reward: [8.227787689538115, 8.124128854009113, 8.002610018047948, 8.327175294685498, -4.918722542040475, -4.514382073796862], time: 257.138
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 21.304774538822404, agent episode reward: [7.49556942037519, 7.35798635077507, 7.157505373525553, 7.531954202870255, -5.042603561651018, -3.195637247072646], time: 254.56
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 21.887650633033655, agent episode reward: [7.5953932170743705, 7.422676097590213, 7.1588014044831585, 7.611336021388387, -5.016681070917566, -2.8838750365849037], time: 259.859
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 26.926005814902403, agent episode reward: [9.23115814172424, 8.883480483726634, 8.738666357493425, 9.129657453469637, -5.6823321949916, -3.3746244265199303], time: 238.83
...Finished total of 60001 episodes.
