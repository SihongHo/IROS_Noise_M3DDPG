0 bad agents
      adv rate for q_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  0 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
1 bad agents
      adv rate for q_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  1 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
2 bad agents
      adv rate for q_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  2 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
3 bad agents
      adv rate for q_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
      adv rate for p_index :  3 [1e-05, 1e-05, 1e-05, 1e-05, 0.001, 0.001]
4 good agents
      adv rate for q_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  4 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
5 good agents
      adv rate for q_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
      adv rate for p_index :  5 [0.001, 0.001, 0.001, 0.001, 1e-05, 1e-05]
Using good policy mmmaddpg and bad policy mmmaddpg with 4 adversaries
Uncertainty type is:  Action ; Uncertainty level is:  0.5
Starting iterations...
mmmaddpg vs mmmaddpg steps: 24975, episodes: 1000, mean episode reward: -22.33494807715198, agent episode reward: [1.1442993743852898, 1.014139910560188, 1.137768991321005, 1.1510739367101996, -13.20196472615914, -13.580265563969519], time: 240.047
mmmaddpg vs mmmaddpg steps: 49975, episodes: 2000, mean episode reward: -13.932778174769668, agent episode reward: [2.872600425621763, 2.5742066312673306, 2.8352689262292277, 2.769389146714957, -8.64772322329461, -16.336520081308333], time: 317.847
mmmaddpg vs mmmaddpg steps: 74975, episodes: 3000, mean episode reward: 12.476350072700654, agent episode reward: [4.675344593362901, 3.9075624784589307, 4.63453553010263, 4.64632003602896, -2.886389846537038, -2.5010227187157317], time: 324.174
mmmaddpg vs mmmaddpg steps: 99975, episodes: 4000, mean episode reward: 18.809126893888067, agent episode reward: [6.410240154744442, 5.42459302832064, 6.252147311217459, 6.512403912408523, -3.123595348659289, -2.666662164143712], time: 329.922
mmmaddpg vs mmmaddpg steps: 124975, episodes: 5000, mean episode reward: 19.44375705144137, agent episode reward: [6.5274106523670365, 5.884965442107062, 6.404290279567506, 6.593072593127257, -3.1977563178839272, -2.7682255978435673], time: 329.245
mmmaddpg vs mmmaddpg steps: 149975, episodes: 6000, mean episode reward: 17.599055801954986, agent episode reward: [5.9709422075104905, 5.408189608815923, 5.697834217279924, 6.0229595449092015, -2.31704731507185, -3.1838224614887056], time: 328.076
mmmaddpg vs mmmaddpg steps: 174975, episodes: 7000, mean episode reward: 21.20648800285398, agent episode reward: [7.339322766768561, 6.793148703871946, 7.067402813533549, 7.282076773818315, -3.702072512828033, -3.573390542310357], time: 332.123
mmmaddpg vs mmmaddpg steps: 199975, episodes: 8000, mean episode reward: 25.08336881694033, agent episode reward: [8.459398991351275, 8.05803171109438, 8.083920991155793, 8.407113736491208, -3.8431152500355164, -4.081981363116814], time: 326.967
mmmaddpg vs mmmaddpg steps: 224975, episodes: 9000, mean episode reward: 31.144799363473904, agent episode reward: [10.34375425773798, 10.003146294608264, 9.973632151129893, 10.350288419368365, -4.320038865984617, -5.205982893385981], time: 330.577
mmmaddpg vs mmmaddpg steps: 249975, episodes: 10000, mean episode reward: 34.19968229283097, agent episode reward: [11.267194775835566, 11.023207126994665, 11.059414210756984, 11.351779931443657, -4.271588495441995, -6.230325256757903], time: 331.347
mmmaddpg vs mmmaddpg steps: 274975, episodes: 11000, mean episode reward: 32.941640682444834, agent episode reward: [10.950534028163354, 10.596886584824656, 10.773583144044537, 11.018229261686301, -4.4088455466876315, -5.988746789586385], time: 330.75
mmmaddpg vs mmmaddpg steps: 299975, episodes: 12000, mean episode reward: 35.84696751346177, agent episode reward: [11.898180444629054, 11.598285107426763, 11.697324494760723, 12.011533317208585, -5.118406652861937, -6.239949197701417], time: 331.906
mmmaddpg vs mmmaddpg steps: 324975, episodes: 13000, mean episode reward: 33.141387494086956, agent episode reward: [11.013457507793687, 10.946328659532933, 10.921442010850646, 11.220364567605937, -5.359835904733833, -5.600369346962412], time: 329.315
mmmaddpg vs mmmaddpg steps: 349975, episodes: 14000, mean episode reward: 30.041080472170368, agent episode reward: [9.86425817698384, 9.806863993412216, 9.844439742021576, 10.076464894892396, -4.4483835578066975, -5.102562777332959], time: 328.819
mmmaddpg vs mmmaddpg steps: 374975, episodes: 15000, mean episode reward: 26.413810112711435, agent episode reward: [9.01090443980118, 8.869318249327742, 8.95856637367122, 9.184724010241673, -5.241006587283866, -4.3686963730465145], time: 330.633
mmmaddpg vs mmmaddpg steps: 399975, episodes: 16000, mean episode reward: 25.58029025509737, agent episode reward: [8.806795792076743, 8.837277402330251, 8.82114474682248, 8.998746053528382, -5.45185904830276, -4.431814691357729], time: 331.864
mmmaddpg vs mmmaddpg steps: 424975, episodes: 17000, mean episode reward: 22.98577423993389, agent episode reward: [8.143531045228908, 8.261573726730969, 8.294348439894062, 8.377945803950464, -4.636340818133767, -5.4552839577367465], time: 332.355
mmmaddpg vs mmmaddpg steps: 449975, episodes: 18000, mean episode reward: 18.64208954779141, agent episode reward: [6.90815172707646, 7.01917291137678, 7.016712442507242, 7.072764625112237, -3.5880677747771594, -5.786644383504148], time: 332.207
mmmaddpg vs mmmaddpg steps: 474975, episodes: 19000, mean episode reward: 16.609302849534856, agent episode reward: [6.752144520317013, 6.874356466641817, 6.917997305192361, 6.908591378865148, -3.6223770912528894, -7.221409730228592], time: 331.135
mmmaddpg vs mmmaddpg steps: 499975, episodes: 20000, mean episode reward: 13.738971841999192, agent episode reward: [5.807882740437656, 5.823154304925217, 5.930661619668178, 5.932117559847687, -3.357549716289856, -6.3972946665896915], time: 330.387
mmmaddpg vs mmmaddpg steps: 524975, episodes: 21000, mean episode reward: 12.05552510711952, agent episode reward: [5.1823448982618245, 5.221144686810247, 5.266836468707565, 5.284972491948895, -3.6936904846964635, -5.206082953912546], time: 331.287
mmmaddpg vs mmmaddpg steps: 549975, episodes: 22000, mean episode reward: 14.654800296739362, agent episode reward: [5.858545027898526, 5.765135408548917, 5.842894296762055, 5.85883397937268, -3.9556525687069435, -4.714955847135874], time: 329.824
mmmaddpg vs mmmaddpg steps: 574975, episodes: 23000, mean episode reward: 10.30165388655406, agent episode reward: [4.750303302100447, 4.753891796360713, 4.805703019886642, 4.804748275507424, -4.400418792054619, -4.4125737152465465], time: 332.388
mmmaddpg vs mmmaddpg steps: 599975, episodes: 24000, mean episode reward: 16.251828648226773, agent episode reward: [5.903250830208496, 5.853798153212279, 5.9960444224533855, 5.95798034315318, -3.457393633156876, -4.001851467643687], time: 329.483
mmmaddpg vs mmmaddpg steps: 624975, episodes: 25000, mean episode reward: 13.440744546808343, agent episode reward: [5.080899849307131, 5.012548504155047, 5.081092811770926, 5.046715124332468, -3.3577900560858396, -3.4227216866713923], time: 329.615
mmmaddpg vs mmmaddpg steps: 649975, episodes: 26000, mean episode reward: 15.10053467391803, agent episode reward: [5.566145085031987, 5.47222107559744, 5.591326134587893, 5.561040122523147, -3.7012240458176877, -3.388973698004752], time: 331.024
mmmaddpg vs mmmaddpg steps: 674975, episodes: 27000, mean episode reward: 16.161838654448456, agent episode reward: [6.256838946798389, 6.174539515477635, 6.173482747687411, 6.128790273812644, -4.480943823149443, -4.090869006178181], time: 327.196
mmmaddpg vs mmmaddpg steps: 699975, episodes: 28000, mean episode reward: 17.600050562305167, agent episode reward: [6.801064752042845, 6.570852644605469, 6.684503095189481, 6.622133400030386, -4.522521965333076, -4.555981364229938], time: 325.072
mmmaddpg vs mmmaddpg steps: 724975, episodes: 29000, mean episode reward: 18.572213576964018, agent episode reward: [6.845468714725084, 6.672598566255938, 6.739960425984614, 6.690453396546262, -3.969433619696188, -4.40683390685169], time: 321.036
mmmaddpg vs mmmaddpg steps: 749975, episodes: 30000, mean episode reward: 23.474171488289056, agent episode reward: [8.134000901936355, 8.01661528240723, 8.031052248194102, 8.007159554319347, -4.391788942501639, -4.322867556066341], time: 319.883
mmmaddpg vs mmmaddpg steps: 774975, episodes: 31000, mean episode reward: 16.958059510405565, agent episode reward: [6.0049797604538036, 5.877959190875708, 5.874933472995449, 5.881779933483097, -2.8938888167428036, -3.787704030659691], time: 319.741
mmmaddpg vs mmmaddpg steps: 799975, episodes: 32000, mean episode reward: 22.332515918829927, agent episode reward: [7.798918647133106, 7.6907135093174315, 7.705342183584444, 7.748148788386476, -4.087110007253138, -4.523497202338392], time: 320.325
mmmaddpg vs mmmaddpg steps: 824975, episodes: 33000, mean episode reward: 22.759436194548556, agent episode reward: [7.990669216255093, 7.952021590973346, 7.956303495649737, 7.8673204290398315, -4.490656764803329, -4.516221772566126], time: 321.06
mmmaddpg vs mmmaddpg steps: 849975, episodes: 34000, mean episode reward: 18.580413417778793, agent episode reward: [6.446107586869426, 6.443906919099989, 6.49854496023078, 6.431555909534824, -3.27008304874752, -3.969618909208707], time: 318.39
mmmaddpg vs mmmaddpg steps: 874975, episodes: 35000, mean episode reward: 19.48338805367528, agent episode reward: [6.867828309276318, 6.8652353381210665, 6.82492021178466, 6.71335428410325, -2.768995781306753, -5.018954308303264], time: 321.081
mmmaddpg vs mmmaddpg steps: 899975, episodes: 36000, mean episode reward: 17.9495072777421, agent episode reward: [6.46978573958446, 6.526477521822144, 6.433032857052706, 6.448161560160585, -3.1389396097300466, -4.78901079114775], time: 319.301
mmmaddpg vs mmmaddpg steps: 924975, episodes: 37000, mean episode reward: 17.786085552942083, agent episode reward: [6.621449627236789, 6.629644529063127, 6.612588614380108, 6.655642566338316, -3.5156969495268764, -5.21754283454938], time: 322.364
mmmaddpg vs mmmaddpg steps: 949975, episodes: 38000, mean episode reward: 20.694818360756432, agent episode reward: [7.605251374804899, 7.529184320217863, 7.52742905108714, 7.585768689795799, -3.6913958935888505, -5.861419181560421], time: 320.876
mmmaddpg vs mmmaddpg steps: 974975, episodes: 39000, mean episode reward: 20.064434111956626, agent episode reward: [7.429564161554947, 7.352151946319299, 7.364995152428431, 7.414957013901984, -3.4023913122391503, -6.094842850008883], time: 320.112
mmmaddpg vs mmmaddpg steps: 999975, episodes: 40000, mean episode reward: 19.081473734145387, agent episode reward: [6.901000676396872, 6.82755498199821, 6.802779404235402, 6.813678470486013, -2.949950870830422, -5.313588928140685], time: 320.531
mmmaddpg vs mmmaddpg steps: 1024975, episodes: 41000, mean episode reward: 20.49772762965643, agent episode reward: [7.177733265602742, 7.093428690318486, 7.051567044126482, 7.196804039618565, -2.81907265796477, -5.2027327520450735], time: 314.674
mmmaddpg vs mmmaddpg steps: 1049975, episodes: 42000, mean episode reward: 21.265913257327863, agent episode reward: [7.7363040207721205, 7.728221628377021, 7.677706514962996, 7.799124093354684, -3.896686202412887, -5.778756797726071], time: 319.09
mmmaddpg vs mmmaddpg steps: 1074975, episodes: 43000, mean episode reward: 20.60507973936729, agent episode reward: [7.298466318183472, 7.249299831361209, 7.2052398319033335, 7.265881047643796, -3.150951878922745, -5.262855410801771], time: 318.753
mmmaddpg vs mmmaddpg steps: 1099975, episodes: 44000, mean episode reward: 19.831105349568322, agent episode reward: [7.140254162438405, 7.104698368068897, 7.165102598656844, 7.210549710923656, -3.2174393661490046, -5.572060124370476], time: 317.639
mmmaddpg vs mmmaddpg steps: 1124975, episodes: 45000, mean episode reward: 19.90212301357337, agent episode reward: [7.121845184177141, 7.158414003898895, 7.092012682700479, 7.1774707599029055, -3.085382488853127, -5.562237128252918], time: 319.719
mmmaddpg vs mmmaddpg steps: 1149975, episodes: 46000, mean episode reward: 19.871837831943118, agent episode reward: [7.056444143475774, 6.981593399836109, 6.963961520544413, 6.998061328571227, -3.6370147671142896, -4.49120779337012], time: 322.57
mmmaddpg vs mmmaddpg steps: 1174975, episodes: 47000, mean episode reward: 23.903558085709605, agent episode reward: [8.225928955107763, 8.073260322181907, 8.106661771434354, 8.087875442149846, -3.5871707111384334, -5.002997694025827], time: 318.184
mmmaddpg vs mmmaddpg steps: 1199975, episodes: 48000, mean episode reward: 24.454787720223642, agent episode reward: [8.189865261760943, 8.085868165815462, 8.113115494513417, 8.163501381849732, -3.5082646793835304, -4.589297904332383], time: 317.501
mmmaddpg vs mmmaddpg steps: 1224975, episodes: 49000, mean episode reward: 22.23396516216232, agent episode reward: [7.485100299406806, 7.464516045104339, 7.574835196587843, 7.668914508612536, -3.066310950431876, -4.8930899371173275], time: 318.675
mmmaddpg vs mmmaddpg steps: 1249975, episodes: 50000, mean episode reward: 23.577214797619817, agent episode reward: [8.045091345206547, 7.878466823938064, 7.907049682359071, 8.01988081329653, -3.1953231791334646, -5.077950688046928], time: 317.251
mmmaddpg vs mmmaddpg steps: 1274975, episodes: 51000, mean episode reward: 23.129326926060262, agent episode reward: [7.805027411841181, 7.757391519987007, 7.712793994504178, 7.842373142406673, -3.013659017218119, -4.974600125460661], time: 316.679
mmmaddpg vs mmmaddpg steps: 1299975, episodes: 52000, mean episode reward: 23.71824952023353, agent episode reward: [7.835682266837791, 7.9583895270163145, 7.929397591684937, 7.968604445448214, -2.7212716231251277, -5.252552687628598], time: 317.929
mmmaddpg vs mmmaddpg steps: 1324975, episodes: 53000, mean episode reward: 21.484525050574806, agent episode reward: [7.006605780068436, 7.070552985799483, 6.993568060606471, 7.171811578431571, -2.8128046927954315, -3.945208661535728], time: 315.494
mmmaddpg vs mmmaddpg steps: 1349975, episodes: 54000, mean episode reward: 26.327495814863504, agent episode reward: [8.771489149727971, 8.676897574337849, 8.703930226735068, 8.900920372867276, -2.9974654286908264, -5.728276080113837], time: 314.243
mmmaddpg vs mmmaddpg steps: 1374975, episodes: 55000, mean episode reward: 21.841439752207286, agent episode reward: [7.324999339790753, 7.301298798442125, 7.269765661672827, 7.458568244197204, -2.853607444635658, -4.659584847259966], time: 316.209
mmmaddpg vs mmmaddpg steps: 1399975, episodes: 56000, mean episode reward: 23.411490528500718, agent episode reward: [8.045108046850773, 7.941116220084201, 7.955238666700439, 7.95705596984755, -3.0838432133294793, -5.4031851616527655], time: 314.206
mmmaddpg vs mmmaddpg steps: 1424975, episodes: 57000, mean episode reward: 25.044013664379655, agent episode reward: [8.354562113223155, 8.311378959927096, 8.383453649869933, 8.477171387400674, -2.99682078931829, -5.485731656722912], time: 318.121
mmmaddpg vs mmmaddpg steps: 1449975, episodes: 58000, mean episode reward: 25.203815221148027, agent episode reward: [8.355738039845328, 8.445373724848334, 8.472994369898638, 8.541817126827544, -2.838603616756246, -5.773504423515573], time: 316.222
mmmaddpg vs mmmaddpg steps: 1474975, episodes: 59000, mean episode reward: 25.23540542105402, agent episode reward: [8.351930957127868, 8.302234666789307, 8.342169591281024, 8.437079541605119, -2.7346027749703254, -5.463406560778978], time: 315.317
mmmaddpg vs mmmaddpg steps: 1499975, episodes: 60000, mean episode reward: 22.680049499059663, agent episode reward: [7.577933139706928, 7.43326056664172, 7.515100500626428, 7.625258226807681, -2.30632149802309, -5.165181436700002], time: 274.465
...Finished total of 60001 episodes.
